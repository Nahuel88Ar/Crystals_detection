{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9983a9-cab5-4e31-9c09-2c7374726f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import cv2\n",
    "import sys\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from io import BytesIO\n",
    "import tempfile\n",
    "matplotlib.use(\"Agg\")  # Headless-safe backend\n",
    "\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.filters import threshold_li\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters import threshold_isodata\n",
    "from skimage import data, filters, measure, morphology, exposure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.morphology import opening, remove_small_objects, remove_small_holes, disk\n",
    "from skimage import morphology, exposure\n",
    "from skimage import color\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import morphological_chan_vese\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import active_contour\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage import draw\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt, label as ndi_label\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy import ndimage\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from xlsxwriter import Workbook\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import json\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "\n",
    "# Streamlit App\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.title(\"Microscopy Image Processing\")\n",
    "\n",
    "# File Upload\n",
    "bf_files = st.file_uploader(\"Upload BF Images (.tif)\", type=[\"tif\"], accept_multiple_files=True)\n",
    "pl_files = st.file_uploader(\"Upload PL Images (.tif)\", type=[\"tif\"], accept_multiple_files=True)\n",
    "\n",
    "# Sort uploaded files\n",
    "if bf_files:\n",
    "    bf_files = sorted(bf_files, key=lambda x: x.name)\n",
    "if pl_files:\n",
    "    pl_files = sorted(pl_files, key=lambda x: x.name)\n",
    "\n",
    "# File Count Info\n",
    "if bf_files and pl_files:\n",
    "    st.success(f\"Found {len(bf_files)} BF files and {len(pl_files)} PL files.\")\n",
    "    if len(bf_files) != len(pl_files):\n",
    "        st.warning(\"The number of BF and PL images does not match. Only matching pairs will be processed.\")\n",
    "\n",
    "    for bf, pl in zip(bf_files, pl_files):\n",
    "        st.write(f\"Processing: {bf.name} and {pl.name}\")\n",
    "\n",
    "# Output Directory\n",
    "output_dir = \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load scale settings\n",
    "@st.cache_data\n",
    "def load_scale_settings():\n",
    "    try:\n",
    "        with open('scale_map.json', 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {\"40\": 5.64039652, \"100\": 13.889}\n",
    "\n",
    "um_to_px_map = load_scale_settings()\n",
    "\n",
    "# Sidebar Scale Input\n",
    "st.sidebar.header(\"Scale Settings\")\n",
    "selected_um = st.sidebar.selectbox(\"Known Distance (µm):\", list(um_to_px_map.keys()))\n",
    "distance_in_px = st.sidebar.text_input(\"Distance in Pixels:\", value=str(um_to_px_map.get(selected_um, \"\")))\n",
    "\n",
    "# Convert to float with error handling\n",
    "try:\n",
    "    s_um = float(selected_um)\n",
    "    d_px = float(distance_in_px)\n",
    "    PIXEL_TO_UM = 1 / (s_um / d_px)\n",
    "    st.success(f\"Calibration result: 1 px = {PIXEL_TO_UM:.4f} µm\")\n",
    "    st.session_state.pixel_to_um = PIXEL_TO_UM\n",
    "except ValueError:\n",
    "    st.error(\"Please enter valid numeric values for scale calibration.\")\n",
    "\n",
    "# Session State Initialization\n",
    "if \"script1_done\" not in st.session_state:\n",
    "    st.session_state.script1_done = False\n",
    "if \"script1_results\" not in st.session_state:\n",
    "    st.session_state.script1_results = []\n",
    "if \"zip_path_1\" not in st.session_state:\n",
    "    st.session_state.zip_path_1 = None\n",
    "\n",
    "# Start Button\n",
    "if st.button(\"Number of cells with crystals\"):\n",
    "    if not bf_files or not pl_files:\n",
    "        st.warning(\"Please upload both BF and PL files.\")\n",
    "    elif len(bf_files) != len(pl_files):\n",
    "        st.error(\"Mismatch in number of BF and PL files.\")\n",
    "    else:\n",
    "        st.session_state.script1_done = True\n",
    "        st.session_state.script1_results.clear()\n",
    "\n",
    "# Processing Logic\n",
    "if st.session_state.script1_done:\n",
    "    st.write(\"🔄 Starting batch processing...\")\n",
    "    all_output_files = []\n",
    "\n",
    "    for bf_file, pl_file in zip(bf_files, pl_files):\n",
    "        #bf_file.seek(0)\n",
    "        #pl_file.seek(0)\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as bf_temp, tempfile.NamedTemporaryFile(delete=False) as pl_temp:\n",
    "            bf_temp.write(bf_file.read())\n",
    "            pl_temp.write(pl_file.read())\n",
    "            bf_path = bf_temp.name\n",
    "            pl_path = pl_temp.name\n",
    "\n",
    "        imageA = cv2.imread(bf_path)\n",
    "        imageB = cv2.imread(pl_path)\n",
    "\n",
    "        if imageA is None or imageB is None:\n",
    "            st.warning(f\"Unable to read {bf_file.name} or {pl_file.name}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        grayA = rgb2gray(imageA)\n",
    "        grayA = exposure.equalize_adapthist(grayA)\n",
    "        grayA = cv2.bilateralFilter((grayA * 255).astype(np.uint8), 9, 75, 75)\n",
    "        threshold = threshold_otsu(grayA)\n",
    "        binary_A = (grayA < threshold).astype(np.uint8) * 255\n",
    "\n",
    "        # Apply morphological operations to clean up the binary mask\n",
    "        binary_A = morphology.opening(binary_A)\n",
    "        binary_A = morphology.remove_small_objects(binary_A.astype(bool), min_size=500)\n",
    "        binary_A = morphology.dilation(binary_A, morphology.disk(4))\n",
    "        binary_A = morphology.remove_small_holes(binary_A, area_threshold=5000)\n",
    "        binary_A = morphology.closing(binary_A, morphology.disk(4))\n",
    "        binary_A = (binary_A > 0).astype(np.uint8) * 255\n",
    "\n",
    "        region_labels_A = label(binary_A)\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        new_label_img = np.zeros_like(region_labels_A, dtype=np.int32)\n",
    "        label_counter = 1\n",
    "        #<1500,>=3,=2,=5,=42\n",
    "\n",
    "        # Compute average threshold based on the mean and standart desviation of region area\n",
    "        #max_area = max([region.area for region in region_props_A])\n",
    "        areas = [region.area for region in region_props_A]\n",
    "        mean_area = np.mean(areas)\n",
    "        std_area = np.std(areas)\n",
    "        average = mean_area + std_area\n",
    "\n",
    "        # Histogram Areas\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(areas, bins=20, color='skyblue', edgecolor='black')\n",
    "        hist_path_Areas = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_Areas.png\")\n",
    "        fig.savefig(hist_path_Areas)\n",
    "        all_output_files.append(hist_path_Areas)\n",
    "        \n",
    "        for region in region_props_A:\n",
    "            if region.area < average:\n",
    "                new_label_img[region.slice][region.image] = label_counter\n",
    "                label_counter += 1\n",
    "            else:\n",
    "                coords = np.column_stack(np.where(region.image))\n",
    "                if len(coords) >= 10:\n",
    "                    n_clusters = 5\n",
    "                    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42).fit(coords)\n",
    "                    for k in range(n_clusters):\n",
    "                        mask = (kmeans.labels_ == k)\n",
    "                        subcoords = coords[mask]\n",
    "                        for (r, c) in subcoords:\n",
    "                            new_label_img[region.slice][r, c] = label_counter\n",
    "                        label_counter += 1\n",
    "\n",
    "        region_labels_A = new_label_img\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        # Ensure binary_A is the correct shape (resize if necessary)\n",
    "        if binary_A.shape != grayA.shape:\n",
    "            binary_A = resize(binary_A, grayA.shape, order=0, preserve_range=True, anti_aliasing=False)\n",
    "\n",
    "        # Convert label image to RGB for annotation\n",
    "        overlay_image = cv2.cvtColor((binary_A > 0).astype(np.uint8) * 255, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Loop through each region and annotate label number\n",
    "        for region in regionprops(region_labels_A):\n",
    "            y, x = region.centroid  # Note: (row, col) = (y, x)\n",
    "            label_id = region.label\n",
    "            cv2.putText(\n",
    "                overlay_image,\n",
    "                str(label_id),\n",
    "                (int(x), int(y)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),  # Red color for text\n",
    "                1,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "        # Save the annotated image\n",
    "        annotated_path = os.path.join(output_dir, f\"{bf_file.name}_Segmented_Cells.png\")\n",
    "        cv2.imwrite(annotated_path, overlay_image)\n",
    "        all_output_files.append(annotated_path)\n",
    "\n",
    "\n",
    "        region_area_df = pd.DataFrame({\n",
    "            \"Region_Label\": [r.label for r in region_props_A],\n",
    "            \"Region_Area (pixels)\": [r.area for r in region_props_A],\n",
    "            \"Region_Area (µm²)\": [r.area * (PIXEL_TO_UM ** 2) for r in region_props_A]\n",
    "        })\n",
    "\n",
    "        region_area_df = region_area_df[region_area_df[\"Region_Area (µm²)\"] > 0]\n",
    "        total_cells = region_area_df[\"Region_Label\"].count() - 1  # Subtract 1 if you're excluding the bottom-right region\n",
    "        region_area_df.loc[\"Total Area\"] = [\"\", \"Total Area\", region_area_df[\"Region_Area (µm²)\"].sum()]\n",
    "        region_area_df.loc[\"Total Cells\"] = [\"\", \"Total Cells\", total_cells]\n",
    "\n",
    "        excel_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Region_Area.xlsx\")\n",
    "        region_area_df.to_excel(excel_path, index=False)\n",
    "\n",
    "        # Histogram A\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayA.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(threshold, color='red', linestyle='--')\n",
    "        hist_path_A = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_A.png\")\n",
    "        fig.savefig(hist_path_A)\n",
    "        all_output_files.append(hist_path_A)\n",
    "\n",
    "        # Image B thresholding\n",
    "        grayB = rgb2gray(imageB)\n",
    "        grayB = exposure.equalize_adapthist(grayB)\n",
    "        grayB = cv2.bilateralFilter((grayB * 255).astype(np.uint8), 9, 75, 75)\n",
    "        mean_intensity = np.mean(grayB)\n",
    "        std_intensity = np.std(grayB)\n",
    "        dynamic_threshold = mean_intensity + 4 * std_intensity\n",
    "        binary_B = (grayB > dynamic_threshold).astype(np.uint8)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayB.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(dynamic_threshold, color='red', linestyle='--')\n",
    "        hist_path_B = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_B.png\")\n",
    "        fig.savefig(hist_path_B)\n",
    "        all_output_files.append(hist_path_B)\n",
    "\n",
    "        overlap = (np.logical_and(cv2.resize(binary_A, (2048, 2048)) > 0, cv2.resize(binary_B, (2048, 2048)) > 0)).astype(np.uint8) * 255\n",
    "        overlap_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Overlap.png\")\n",
    "        cv2.imwrite(overlap_path, overlap)\n",
    "        all_output_files.append(overlap_path)\n",
    "\n",
    "        # Region associations\n",
    "        region_props = regionprops(label(overlap))\n",
    "        cell_props = region_props_A\n",
    "        crystal_to_cell = []\n",
    "        cell_to_crystals = defaultdict(list)\n",
    "\n",
    "        for region in region_props:\n",
    "            region_coords = set(map(tuple, region.coords))\n",
    "            best_match = None\n",
    "            max_overlap = 0\n",
    "            for cell in cell_props:\n",
    "                cell_coords = set(map(tuple, cell.coords))\n",
    "                overlap_area = len(region_coords & cell_coords)\n",
    "                if overlap_area > 0:\n",
    "                    cell_to_crystals[cell.label].append(region.label)\n",
    "                if overlap_area > max_overlap:\n",
    "                    max_overlap = overlap_area\n",
    "                    best_match_cell = cell.label\n",
    "            crystal_to_cell.append({\n",
    "                \"Region_Label\": region.label,\n",
    "                \"Associated_Cell\": best_match_cell,\n",
    "                \"Overlap (pixels)\": max_overlap,\n",
    "                \"Region_Area (pixels)\": region.area,\n",
    "                \"Region_Area (µm²)\": region.area * (PIXEL_TO_UM ** 2)\n",
    "            })\n",
    "\n",
    "            # ✅ Store the crystal label for the matched cell\n",
    "            if best_match_cell is not None:\n",
    "                cell_to_crystals[best_match_cell].append(region.label)\n",
    "\n",
    "        df_mapping = pd.DataFrame(crystal_to_cell)\n",
    "        df_mapping = df_mapping[(df_mapping[\"Region_Area (µm²)\"] < 10) & (df_mapping[\"Overlap (pixels)\"] > 0)]\n",
    "        df_mapping[\"Associated_Cell_Count\"] = df_mapping[\"Associated_Cell\"].map(df_mapping[\"Associated_Cell\"].value_counts())\n",
    "        df_mapping[\"Total_Cells_with_crystals\"] = df_mapping[\"Associated_Cell\"].nunique()\n",
    "        df_mapping.loc[\"Total\"] = [\"\", \"\", \"\", \"Total Area Crystals\", df_mapping[\"Region_Area (µm²)\"].sum(), \"\", \"\"]\n",
    "\n",
    "        #cell_crystal_df = pd.DataFrame([\n",
    "        #    {\"Cell_Label\": k, \"Crystal_Labels\": \", \".join(map(str, v)), \"Crystal_Count\": len(v)}\n",
    "        #    for k, v in cell_to_crystals.items()\n",
    "        #])\n",
    "\n",
    "        # --- Optional: Save cell-to-crystal list (for debugging or export) ---\n",
    "        cell_crystal_df = pd.DataFrame([\n",
    "            {\n",
    "                \"Cell_Label\": cell_label,\n",
    "                \"Crystal_Labels\": \", \".join(map(str, crystals)),\n",
    "                \"Crystal_Count\": len(crystals)\n",
    "            }\n",
    "            for cell_label, crystals in cell_to_crystals.items()\n",
    "        ])\n",
    "        \n",
    "        merged_df = df_mapping.merge(region_area_df, left_on=\"Associated_Cell\", right_on=\"Region_Label\", how=\"inner\")\n",
    "\n",
    "        grouped_xlsx_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_All_Datasets.xlsx\")\n",
    "        with pd.ExcelWriter(grouped_xlsx_path, engine=\"xlsxwriter\") as writer:\n",
    "            region_area_df.to_excel(writer, sheet_name=\"Cells\", index=False)\n",
    "            df_mapping.to_excel(writer, sheet_name=\"Crystals\", index=False)\n",
    "            merged_df.to_excel(writer, sheet_name=\"Cells + Crystals\", index=False)\n",
    "            cell_crystal_df.to_excel(writer, sheet_name=\"Cell-Crystal Map\", index=False)\n",
    "\n",
    "        # Annotated Image\n",
    "        annotated_image = cv2.cvtColor(imageA, cv2.COLOR_GRAY2BGR) if imageA.ndim == 2 else imageA.copy()\n",
    "        for _, mapping in df_mapping.iterrows():\n",
    "            if pd.notna(mapping[\"Associated_Cell\"]):\n",
    "                region = next((r for r in region_props if r.label == mapping[\"Region_Label\"]), None)\n",
    "                if region:\n",
    "                    min_row, min_col, max_row, max_col = region.bbox\n",
    "                    cv2.rectangle(annotated_image, (min_col, min_row), (max_col, max_row), (0, 255, 0), 2)\n",
    "                    cv2.putText(annotated_image, f\"Cell {int(mapping['Associated_Cell'])}\", (min_col, max(min_row - 5, 10)),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "        annotated_image_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Annotated.png\")\n",
    "        cv2.imwrite(annotated_image_path, annotated_image)\n",
    "        all_output_files.append(annotated_image_path)\n",
    "\n",
    "        # Save session result\n",
    "        st.session_state.script1_results.append({\n",
    "            \"bf_name\": bf_file.name,\n",
    "            \"excel_path\": grouped_xlsx_path,\n",
    "            \"annotated_img_path\": annotated_image_path,\n",
    "            \"overlap_path\": overlap_path,\n",
    "            \"hist_A_path\": hist_path_A,\n",
    "            \"hist_B_path\": hist_path_B,\n",
    "        })\n",
    "\n",
    "    # Create ZIP\n",
    "    zip_path_1 = os.path.join(output_dir, \"All_Images_histograms.zip\")\n",
    "    with zipfile.ZipFile(zip_path_1, 'w') as zipf_1:\n",
    "        for file_path in all_output_files:\n",
    "            zipf_1.write(file_path, arcname=os.path.basename(file_path))\n",
    "    st.session_state.zip_path_1 = zip_path_1\n",
    "    st.success(\"✅ Processing complete!\")\n",
    "\n",
    "# Display Outputs and Download Buttons\n",
    "if st.session_state.script1_results:\n",
    "    st.header(\"📦 Results\")\n",
    "\n",
    "    for result1 in st.session_state.script1_results:\n",
    "        st.subheader(f\"📁 {result1['bf_name']}\")\n",
    "        st.image(result1[\"annotated_img_path\"], caption=\"Detections crystals\")\n",
    "        st.image(result1[\"overlap_path\"], caption=\"Correlation\")\n",
    "\n",
    "        with open(result1[\"excel_path\"], \"rb\") as f1:\n",
    "            st.download_button(\"📊 Download Dataset\", f1, file_name=os.path.basename(result1[\"excel_path\"]),key=f\"download_button_{os.path.basename(result1['excel_path'])}\")\n",
    "\n",
    "        #with open(result1[\"hist_A_path\"], \"rb\") as f1:\n",
    "        #    st.download_button(\"📈 Download Histogram A\", f1, file_name=os.path.basename(result1[\"hist_A_path\"]))\n",
    "\n",
    "        #with open(result1[\"hist_B_path\"], \"rb\") as f1:\n",
    "        #    st.download_button(\"📉 Download Histogram B\", f1, file_name=os.path.basename(result1[\"hist_B_path\"]))\n",
    "\n",
    "    with open(st.session_state.zip_path_1, \"rb\") as zf_1:\n",
    "        st.download_button(\"🗂️ Download All Images and Histograms\", zf_1, file_name=\"All_Images_histograms.zip\")\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Session State Initialization\n",
    "if \"script2_done\" not in st.session_state:\n",
    "    st.session_state.script2_done = False\n",
    "if \"script2_results\" not in st.session_state:\n",
    "    st.session_state.script2_results = []\n",
    "if \"zip_path_2\" not in st.session_state:\n",
    "    st.session_state.zip_path_2 = None\n",
    "\n",
    "# Start Button\n",
    "if st.button(\"Areas\"):\n",
    "    if not bf_files or not pl_files:\n",
    "        st.warning(\"Please upload both BF and PL files.\")\n",
    "    elif len(bf_files) != len(pl_files):\n",
    "        st.error(\"Mismatch in number of BF and PL files.\")\n",
    "    else:\n",
    "        st.session_state.script2_done = True\n",
    "        st.session_state.script2_results.clear()\n",
    "\n",
    "# Processing Logic\n",
    "if st.session_state.script2_done:\n",
    "    st.write(\"🔄 Starting batch processing...\")\n",
    "    all_output_files = []\n",
    "\n",
    "    for bf_file, pl_file in zip(bf_files, pl_files):\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as bf_temp, tempfile.NamedTemporaryFile(delete=False) as pl_temp:\n",
    "            bf_temp.write(bf_file.read())\n",
    "            pl_temp.write(pl_file.read())\n",
    "            bf_path = bf_temp.name\n",
    "            pl_path = pl_temp.name\n",
    "\n",
    "        imageA = cv2.imread(bf_path)\n",
    "        imageB = cv2.imread(pl_path)\n",
    "\n",
    "        if imageA is None or imageB is None:\n",
    "            st.warning(f\"Unable to read {bf_file.name} or {pl_file.name}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        grayA = rgb2gray(imageA)\n",
    "        grayA = exposure.equalize_adapthist(grayA)\n",
    "        grayA = cv2.bilateralFilter((grayA * 255).astype(np.uint8), 9, 75, 75)\n",
    "        threshold = threshold_otsu(grayA)\n",
    "        binary_A = (grayA < threshold).astype(np.uint8) * 255\n",
    "\n",
    "        # Apply morphological operations to clean up the binary mask\n",
    "        binary_A = morphology.opening(binary_A)\n",
    "        binary_A = morphology.remove_small_objects(binary_A.astype(bool), min_size=500)\n",
    "        binary_A = morphology.dilation(binary_A, morphology.disk(4))\n",
    "        binary_A = morphology.remove_small_holes(binary_A, area_threshold=5000)\n",
    "        binary_A = morphology.closing(binary_A, morphology.disk(4))\n",
    "        binary_A = (binary_A > 0).astype(np.uint8) * 255\n",
    "\n",
    "        region_labels_A = label(binary_A)\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        new_label_img = np.zeros_like(region_labels_A, dtype=np.int32)\n",
    "        label_counter = 1\n",
    "        #<1500,>=3,=2,=5,=42\n",
    "\n",
    "        # Compute average threshold based on the mean and standart desviation of region area\n",
    "        #max_area = max([region.area for region in region_props_A])\n",
    "        areas = [region.area for region in region_props_A]\n",
    "        mean_area = np.mean(areas)\n",
    "        std_area = np.std(areas)\n",
    "        average = mean_area + std_area\n",
    "\n",
    "        # Histogram Areas\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(areas, bins=20, color='skyblue', edgecolor='black')\n",
    "        hist_path_Areas = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_Areas.png\")\n",
    "        fig.savefig(hist_path_Areas)\n",
    "        all_output_files.append(hist_path_Areas)\n",
    "        \n",
    "        for region in region_props_A:\n",
    "            if region.area < average:\n",
    "                new_label_img[region.slice][region.image] = label_counter\n",
    "                label_counter += 1\n",
    "            else:\n",
    "                coords = np.column_stack(np.where(region.image))\n",
    "                if len(coords) >= 10:\n",
    "                    n_clusters = 5\n",
    "                    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42).fit(coords)\n",
    "                    for k in range(n_clusters):\n",
    "                        mask = (kmeans.labels_ == k)\n",
    "                        subcoords = coords[mask]\n",
    "                        for (r, c) in subcoords:\n",
    "                            new_label_img[region.slice][r, c] = label_counter\n",
    "                        label_counter += 1\n",
    "\n",
    "        region_labels_A = new_label_img\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        # Ensure binary_A is the correct shape (resize if necessary)\n",
    "        if binary_A.shape != grayA.shape:\n",
    "            binary_A = resize(binary_A, grayA.shape, order=0, preserve_range=True, anti_aliasing=False)\n",
    "\n",
    "        # Convert label image to RGB for annotation\n",
    "        overlay_image = cv2.cvtColor((binary_A > 0).astype(np.uint8) * 255, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Loop through each region and annotate label number\n",
    "        for region in regionprops(region_labels_A):\n",
    "            y, x = region.centroid  # Note: (row, col) = (y, x)\n",
    "            label_id = region.label\n",
    "            cv2.putText(\n",
    "                overlay_image,\n",
    "                str(label_id),\n",
    "                (int(x), int(y)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),  # Red color for text\n",
    "                1,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "        # Save the annotated image\n",
    "        annotated_path = os.path.join(output_dir, f\"{bf_file.name}_Segmented_Cells.png\")\n",
    "        cv2.imwrite(annotated_path, overlay_image)\n",
    "        all_output_files.append(annotated_path)\n",
    "\n",
    "        region_area_df = pd.DataFrame({\n",
    "            \"Region_Label\": [r.label for r in region_props_A],\n",
    "            \"Region_Area (pixels)\": [r.area for r in region_props_A],\n",
    "            \"Region_Area (µm²)\": [r.area * (PIXEL_TO_UM ** 2) for r in region_props_A]\n",
    "        })\n",
    "\n",
    "        region_area_df = region_area_df[region_area_df[\"Region_Area (µm²)\"] > 0]\n",
    "        total_cells = region_area_df[\"Region_Label\"].count() - 1  # Subtract 1 if you're excluding the bottom-right region\n",
    "        region_area_df.loc[\"Total Area\"] = [\"\", \"Total Area\", region_area_df[\"Region_Area (µm²)\"].sum()]\n",
    "        region_area_df.loc[\"Total Cells\"] = [\"\", \"Total Cells\", total_cells]\n",
    "\n",
    "        excel_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Region_Area.xlsx\")\n",
    "        region_area_df.to_excel(excel_path, index=False)\n",
    "\n",
    "        # Histogram A\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayA.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(threshold, color='red', linestyle='--')\n",
    "        hist_path_A = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_A.png\")\n",
    "        fig.savefig(hist_path_A)\n",
    "        all_output_files.append(hist_path_A)\n",
    "\n",
    "        # Image B thresholding\n",
    "        grayB = rgb2gray(imageB)\n",
    "        grayB = exposure.equalize_adapthist(grayB)\n",
    "        grayB = cv2.bilateralFilter((grayB * 255).astype(np.uint8), 9, 75, 75)\n",
    "        mean_intensity = np.mean(grayB)\n",
    "        std_intensity = np.std(grayB)\n",
    "        dynamic_threshold = mean_intensity + 4.6 * std_intensity\n",
    "        binary_B = (grayB > dynamic_threshold).astype(np.uint8)\n",
    "\n",
    "        binary_B = opening(binary_B)# Remove small noise\n",
    "        #binary_B= morphology.dilation(binary_B, morphology.disk(4)) # Dilation\n",
    "        #binary_B = morphology.closing(binary_B, morphology.disk(4)) # Closing\n",
    "        binary_B = (binary_B > 0).astype(np.uint8) * 255 # Convert back to binary\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayB.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(dynamic_threshold, color='red', linestyle='--')\n",
    "        hist_path_B = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_B.png\")\n",
    "        fig.savefig(hist_path_B)\n",
    "        all_output_files.append(hist_path_B)\n",
    "\n",
    "        overlap = (np.logical_and(cv2.resize(binary_A, (2048, 2048)) > 0, cv2.resize(binary_B, (2048, 2048)) > 0)).astype(np.uint8) * 255\n",
    "        overlap_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Overlap.png\")\n",
    "        cv2.imwrite(overlap_path, overlap)\n",
    "        all_output_files.append(overlap_path)\n",
    "\n",
    "        # Region associations\n",
    "        region_props = regionprops(label(overlap))\n",
    "        cell_props = region_props_A\n",
    "        crystal_to_cell = []\n",
    "        cell_to_crystals = defaultdict(list)\n",
    "\n",
    "        for region in region_props:\n",
    "            region_coords = set(map(tuple, region.coords))\n",
    "            best_match = None\n",
    "            max_overlap = 0\n",
    "            for cell in cell_props:\n",
    "                cell_coords = set(map(tuple, cell.coords))\n",
    "                overlap_area = len(region_coords & cell_coords)\n",
    "                if overlap_area > 0:\n",
    "                    cell_to_crystals[cell.label].append(region.label)\n",
    "                if overlap_area > max_overlap:\n",
    "                    max_overlap = overlap_area\n",
    "                    best_match_cell = cell.label\n",
    "            crystal_to_cell.append({\n",
    "                \"Region_Label\": region.label,\n",
    "                \"Associated_Cell\": best_match_cell,\n",
    "                \"Overlap (pixels)\": max_overlap,\n",
    "                \"Region_Area (pixels)\": region.area,\n",
    "                \"Region_Area (µm²)\": region.area * (PIXEL_TO_UM ** 2)\n",
    "            })\n",
    "\n",
    "            # ✅ Store the crystal label for the matched cell\n",
    "            if best_match_cell is not None:\n",
    "                cell_to_crystals[best_match_cell].append(region.label)\n",
    "\n",
    "        df_mapping = pd.DataFrame(crystal_to_cell)\n",
    "        df_mapping = df_mapping[(df_mapping[\"Region_Area (µm²)\"] < 6) & (df_mapping[\"Overlap (pixels)\"] > 0)]\n",
    "        df_mapping[\"Associated_Cell_Count\"] = df_mapping[\"Associated_Cell\"].map(df_mapping[\"Associated_Cell\"].value_counts())\n",
    "        df_mapping[\"Total_Cells_with_crystals\"] = df_mapping[\"Associated_Cell\"].nunique()\n",
    "        df_mapping.loc[\"Total\"] = [\"\", \"\", \"\", \"Total Area Crystals\", df_mapping[\"Region_Area (µm²)\"].sum(), \"\", \"\"]\n",
    "\n",
    "        #cell_crystal_df = pd.DataFrame([\n",
    "        #    {\"Cell_Label\": k, \"Crystal_Labels\": \", \".join(map(str, v)), \"Crystal_Count\": len(v)}\n",
    "        #    for k, v in cell_to_crystals.items()\n",
    "        #])\n",
    "\n",
    "        # --- Optional: Save cell-to-crystal list (for debugging or export) ---\n",
    "        cell_crystal_df = pd.DataFrame([\n",
    "            {\n",
    "                \"Cell_Label\": cell_label,\n",
    "                \"Crystal_Labels\": \", \".join(map(str, crystals)),\n",
    "                \"Crystal_Count\": len(crystals)\n",
    "            }\n",
    "            for cell_label, crystals in cell_to_crystals.items()\n",
    "        ])\n",
    "        \n",
    "        merged_df = df_mapping.merge(region_area_df, left_on=\"Associated_Cell\", right_on=\"Region_Label\", how=\"inner\")\n",
    "\n",
    "        #-----------------------------------------------------------------------------------------\n",
    "        # Initialize the column with NaNs\n",
    "        merged_df[\"Crystal/Cell Area (%)\"] = pd.NA\n",
    "\n",
    "        # Calculate percentage only for rows except the last two\n",
    "        merged_df.loc[:-3, \"Crystal/Cell Area (%)\"] = (\n",
    "            merged_df.loc[:-3, \"Region_Area (µm²)_x\"] / merged_df.loc[:-3, \"Region_Area (µm²)_y\"] * 100\n",
    "        )\n",
    "        #-------------------------------------------\n",
    "\n",
    "        grouped_xlsx_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_All_Datasets.xlsx\")\n",
    "        with pd.ExcelWriter(grouped_xlsx_path, engine=\"xlsxwriter\") as writer:\n",
    "            region_area_df.to_excel(writer, sheet_name=\"Cells\", index=False)\n",
    "            df_mapping.to_excel(writer, sheet_name=\"Crystals\", index=False)\n",
    "            merged_df.to_excel(writer, sheet_name=\"Cells + Crystals\", index=False)\n",
    "            cell_crystal_df.to_excel(writer, sheet_name=\"Cell-Crystal Map\", index=False)\n",
    "\n",
    "        # Annotated Image\n",
    "        annotated_image = cv2.cvtColor(imageA, cv2.COLOR_GRAY2BGR) if imageA.ndim == 2 else imageA.copy()\n",
    "        for _, mapping in df_mapping.iterrows():\n",
    "            if pd.notna(mapping[\"Associated_Cell\"]):\n",
    "                region = next((r for r in region_props if r.label == mapping[\"Region_Label\"]), None)\n",
    "                if region:\n",
    "                    min_row, min_col, max_row, max_col = region.bbox\n",
    "                    cv2.rectangle(annotated_image, (min_col, min_row), (max_col, max_row), (0, 255, 0), 2)\n",
    "                    cv2.putText(annotated_image, f\"Cell {int(mapping['Associated_Cell'])}\", (min_col, max(min_row - 5, 10)),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "        annotated_image_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Annotated.png\")\n",
    "        cv2.imwrite(annotated_image_path, annotated_image)\n",
    "        all_output_files.append(annotated_image_path)\n",
    "\n",
    "        # Save session result\n",
    "        st.session_state.script2_results.append({\n",
    "            \"bf_name\": bf_file.name,\n",
    "            \"excel_path\": grouped_xlsx_path,\n",
    "            \"annotated_img_path\": annotated_image_path,\n",
    "            \"overlap_path\": overlap_path,\n",
    "            \"hist_A_path\": hist_path_A,\n",
    "            \"hist_B_path\": hist_path_B,\n",
    "        })\n",
    "\n",
    "    # Create ZIP\n",
    "    zip_path_2 = os.path.join(output_dir, \"All_Images_histograms.zip\")\n",
    "    with zipfile.ZipFile(zip_path_2, 'w') as zipf_2:\n",
    "        for file_path in all_output_files:\n",
    "            zipf_2.write(file_path, arcname=os.path.basename(file_path))\n",
    "    st.session_state.zip_path_2 = zip_path_2\n",
    "    st.success(\"✅ Processing complete!\")\n",
    "\n",
    "# Display Outputs and Download Buttons\n",
    "if st.session_state.script2_results:\n",
    "    st.header(\"📦 Results\")\n",
    "\n",
    "    for result2 in st.session_state.script2_results:\n",
    "        st.subheader(f\"📁 {result2['bf_name']}\")\n",
    "        st.image(result2[\"annotated_img_path\"], caption=\"Detection crystals\")\n",
    "        st.image(result2[\"overlap_path\"], caption=\"Correlation\")\n",
    "\n",
    "        with open(result2[\"excel_path\"], \"rb\") as f2:\n",
    "            st.download_button(\"📊 Download Dataset\", f2, file_name=os.path.basename(result2[\"excel_path\"]),key=f\"download_button_{os.path.basename(result2['excel_path'])}\")\n",
    "\n",
    "        #with open(result2[\"hist_A_path\"], \"rb\") as f2:\n",
    "        #    st.download_button(\"📈 Download Histogram A\", f2, file_name=os.path.basename(result2[\"hist_A_path\"]))\n",
    "\n",
    "        #with open(result2[\"hist_B_path\"], \"rb\") as f2:\n",
    "        #    st.download_button(\"📉 Download Histogram B\", f2, file_name=os.path.basename(result2[\"hist_B_path\"]))\n",
    "\n",
    "    with open(st.session_state.zip_path_2, \"rb\") as zf_2:\n",
    "        st.download_button(\"🗂️ Download All Images and Histograms\", zf_2, file_name=\"All_Images_histograms.zip\")\n",
    "\n",
    "# Session State Initialization\n",
    "if \"script3_done\" not in st.session_state:\n",
    "    st.session_state.script3_done = False\n",
    "if \"script3_results\" not in st.session_state:\n",
    "    st.session_state.script3_results = []\n",
    "if \"zip_path_3\" not in st.session_state:\n",
    "    st.session_state.zip_path_3 = None\n",
    "\n",
    "# Start Button\n",
    "if st.button(\"Number of cells\"):\n",
    "    if not bf_files or not pl_files:\n",
    "        st.warning(\"Please upload both BF and PL files.\")\n",
    "    elif len(bf_files) != len(pl_files):\n",
    "        st.error(\"Mismatch in number of BF and PL files.\")\n",
    "    else:\n",
    "        st.session_state.script3_done = True\n",
    "        st.session_state.script3_results.clear()\n",
    "\n",
    "# Processing Logic\n",
    "if st.session_state.script3_done:\n",
    "    st.write(\"🔄 Starting batch processing...\")\n",
    "    all_output_files = []\n",
    "\n",
    "    for bf_file, pl_file in zip(bf_files, pl_files):\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as bf_temp, tempfile.NamedTemporaryFile(delete=False) as pl_temp:\n",
    "            bf_temp.write(bf_file.read())\n",
    "            pl_temp.write(pl_file.read())\n",
    "            bf_path = bf_temp.name\n",
    "            pl_path = pl_temp.name\n",
    "\n",
    "        imageA = cv2.imread(bf_path)\n",
    "        imageB = cv2.imread(pl_path)\n",
    "\n",
    "        if imageA is None or imageB is None:\n",
    "            st.warning(f\"Unable to read {bf_file.name} or {pl_file.name}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Convert BF image to grayscale and enhance contrast\n",
    "        grayA = rgb2gray(imageA)\n",
    "        # Adaptive histogram equalization\n",
    "        grayA = exposure.equalize_adapthist(grayA)\n",
    "        # Noise reduction\n",
    "        grayA = cv2.bilateralFilter((grayA * 255).astype(np.uint8), 9, 75, 75)\n",
    "        # Compute threshold using Li's method\n",
    "        threshold = threshold_otsu(grayA)\n",
    "        # Apply thresholding\n",
    "        binary_A = (grayA < threshold).astype(np.uint8) * 255\n",
    "    \n",
    "        # Apply morphological operations to clean up the binary mask\n",
    "        binary_A = morphology.opening(binary_A)\n",
    "        binary_A = morphology.remove_small_objects(binary_A.astype(bool), min_size=500)\n",
    "        binary_A = morphology.dilation(binary_A, morphology.disk(4))\n",
    "        binary_A = morphology.remove_small_holes(binary_A, area_threshold=5000)\n",
    "        binary_A = morphology.closing(binary_A, morphology.disk(4))\n",
    "        binary_A = (binary_A > 0).astype(np.uint8) * 255\n",
    "    \n",
    "        #Label connected regions in binary mask\n",
    "        region_labels_A = label(binary_A)\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        new_label_img = np.zeros_like(region_labels_A, dtype=np.int32)\n",
    "        label_counter = 1\n",
    "        #<1500,>=3,=2,=5,=42\n",
    "\n",
    "        # Compute average threshold based on the mean and standart desviation of region area\n",
    "        #max_area = max([region.area for region in region_props_A])\n",
    "        areas = [region.area for region in region_props_A]\n",
    "        mean_area = np.mean(areas)\n",
    "        std_area = np.std(areas)\n",
    "        average = mean_area + std_area\n",
    "\n",
    "        # Histogram Areas\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(areas, bins=20, color='skyblue', edgecolor='black')\n",
    "        hist_path_Areas = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_Areas.png\")\n",
    "        fig.savefig(hist_path_Areas)\n",
    "        all_output_files.append(hist_path_Areas)\n",
    "        \n",
    "        for region in region_props_A:\n",
    "            if region.area < average:\n",
    "                new_label_img[region.slice][region.image] = label_counter\n",
    "                label_counter += 1\n",
    "            else:\n",
    "                coords = np.column_stack(np.where(region.image))\n",
    "                if len(coords) >= 10:\n",
    "                    n_clusters = 5\n",
    "                    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42).fit(coords)\n",
    "                    for k in range(n_clusters):\n",
    "                        mask = (kmeans.labels_ == k)\n",
    "                        subcoords = coords[mask]\n",
    "                        for (r, c) in subcoords:\n",
    "                            new_label_img[region.slice][r, c] = label_counter\n",
    "                        label_counter += 1\n",
    "\n",
    "        region_labels_A = new_label_img\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        # Ensure binary_A is the correct shape (resize if necessary)\n",
    "        if binary_A.shape != grayA.shape:\n",
    "            binary_A = resize(binary_A, grayA.shape, order=0, preserve_range=True, anti_aliasing=False)\n",
    "\n",
    "        # Convert label image to RGB for annotation\n",
    "        overlay_image = cv2.cvtColor((binary_A > 0).astype(np.uint8) * 255, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Loop through each region and annotate label number\n",
    "        for region in regionprops(region_labels_A):\n",
    "            y, x = region.centroid  # Note: (row, col) = (y, x)\n",
    "            label_id = region.label\n",
    "            cv2.putText(\n",
    "                overlay_image,\n",
    "                str(label_id),\n",
    "                (int(x), int(y)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),  # Red color for text\n",
    "                1,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "        # Save the annotated image\n",
    "        annotated_path = os.path.join(output_dir, f\"{bf_file.name}_Segmented_Annotated.png\")\n",
    "        cv2.imwrite(annotated_path, overlay_image)\n",
    "        all_output_files.append(annotated_path)\n",
    "            \n",
    "        filtered_binary_A = np.zeros_like(binary_A)\n",
    "        for prop in region_props_A:\n",
    "            if prop.area > 0:\n",
    "                min_row, min_col, max_row, max_col = prop.bbox\n",
    "                filtered_binary_A[min_row:max_row, min_col:max_col] = (\n",
    "                    region_labels_A[min_row:max_row, min_col:max_col] == prop.label\n",
    "                )\n",
    "\n",
    "        filtered_binary_A = (filtered_binary_A > 0).astype(np.uint8) * 255\n",
    "\n",
    "        px_per_um = um_to_px_map[selected_um]  # µm per pixel\n",
    "\n",
    "        # Create a DataFrame for the regions with their area in µm²\n",
    "        region_area_df = pd.DataFrame({\n",
    "            \"Region_Label\": [region.label for region in region_props_A],\n",
    "            \"Region_Area (pixels)\": [region.area for region in region_props_A],\n",
    "            \"Region_Area (µm²)\": [r.area * (PIXEL_TO_UM ** 2) for r in region_props_A]\n",
    "        })\n",
    "    \n",
    "        region_area_df = region_area_df[region_area_df[\"Region_Area (µm²)\"] > 0]\n",
    "        total_cells = region_area_df[\"Region_Label\"].count() - 1  # Subtract 1 if you're excluding the bottom-right region\n",
    "        region_area_df.loc[\"Total Area\"] = [\"\", \"Total Area\", region_area_df[\"Region_Area (µm²)\"].sum()]\n",
    "        region_area_df.loc[\"Total Cells\"] = [\"\", \"Total Cells\", total_cells]\n",
    "\n",
    "        excel_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Region_Area.xlsx\")\n",
    "        region_area_df.to_excel(excel_path, index=False)\n",
    "\n",
    "        # Histogram A\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayA.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(threshold, color='red', linestyle='--')\n",
    "        hist_path_A = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_A.png\")\n",
    "        fig.savefig(hist_path_A)\n",
    "        all_output_files.append(hist_path_A)\n",
    "\n",
    "        # Save session result\n",
    "        st.session_state.script3_results.append({\n",
    "            \"bf_name\": bf_file.name,\n",
    "            \"annotated_path\": annotated_path,\n",
    "            \"hist_A_path\": hist_path_A,\n",
    "            \"hist_path_Areas\": hist_path_Areas,\n",
    "            \"excel_path\": excel_path,\n",
    "        })\n",
    "\n",
    "    # Create ZIP\n",
    "    zip_path_3 = os.path.join(output_dir, \"All_Images_histograms.zip\")\n",
    "    with zipfile.ZipFile(zip_path_3, 'w') as zipf_3:\n",
    "        for file_path in all_output_files:\n",
    "            zipf_3.write(file_path, arcname=os.path.basename(file_path))\n",
    "    st.session_state.zip_path_3 = zip_path_3\n",
    "    st.success(\"✅ Processing complete!\")\n",
    "\n",
    "# Display Outputs and Download Buttons\n",
    "if st.session_state.script3_results:\n",
    "    st.header(\"📦 Results\")\n",
    "\n",
    "    for result3 in st.session_state.script3_results:\n",
    "        st.subheader(f\"📁 {result3['bf_name']}\")\n",
    "        st.image(result3[\"annotated_path\"], caption=\"Segmented Image\")\n",
    "        st.image(result3[\"hist_path_Areas\"], caption=\"Areas Histogram\")\n",
    "        st.image(result3[\"hist_A_path\"], caption=\"Pixels Intensity Histogram\")\n",
    "\n",
    "        with open(result3[\"excel_path\"], \"rb\") as f3:\n",
    "            st.download_button(\"📊 Download Dataset\", f3, file_name=os.path.basename(result3[\"excel_path\"]),key=f\"download_button_{os.path.basename(result3['excel_path'])}\")\n",
    "\n",
    "        #with open(result2[\"hist_A_path\"], \"rb\") as f2:\n",
    "        #    st.download_button(\"📈 Download Histogram A\", f2, file_name=os.path.basename(result2[\"hist_A_path\"]))\n",
    "\n",
    "        #with open(result2[\"hist_B_path\"], \"rb\") as f2:\n",
    "        #    st.download_button(\"📉 Download Histogram B\", f2, file_name=os.path.basename(result2[\"hist_B_path\"]))\n",
    "\n",
    "    with open(st.session_state.zip_path_3, \"rb\") as zf_3:\n",
    "        st.download_button(\"🗂️ Download All Images and Histograms\", zf_3, file_name=\"All_Images_histograms.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
