{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42efb235-ddde-4cc8-8b31-f5832b6c40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import cv2\n",
    "import sys\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from io import BytesIO\n",
    "import tempfile\n",
    "matplotlib.use(\"Agg\")  # Headless-safe backend\n",
    "\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.filters import threshold_li\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters import threshold_isodata\n",
    "from skimage import data, filters, measure, morphology, exposure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.morphology import opening, remove_small_objects, remove_small_holes, disk\n",
    "from skimage import morphology, exposure\n",
    "from skimage import color\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import morphological_chan_vese\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import active_contour\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage import draw\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt, label as ndi_label\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy import ndimage\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from xlsxwriter import Workbook\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import json\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Streamlit App\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.title(\"Microscopy Image Processing\")\n",
    "\n",
    "# Initialize rerun flag in session_state if not present\n",
    "if \"rerun_flag\" not in st.session_state:\n",
    "    st.session_state.rerun_flag = False\n",
    "\n",
    "# File Upload\n",
    "bf_files = st.file_uploader(\"Upload BF Images (.tif)\", type=[\"tif\"], accept_multiple_files=True)\n",
    "pl_files = st.file_uploader(\"Upload PL Images (.tif)\", type=[\"tif\"], accept_multiple_files=True)\n",
    "\n",
    "# Sort uploaded files\n",
    "if bf_files:\n",
    "    bf_files = sorted(bf_files, key=lambda x: x.name)\n",
    "if pl_files:\n",
    "    pl_files = sorted(pl_files, key=lambda x: x.name)\n",
    "\n",
    "# File Count Info\n",
    "if bf_files and pl_files:\n",
    "    st.success(f\"Found {len(bf_files)} BF files and {len(pl_files)} PL files.\")\n",
    "    if len(bf_files) != len(pl_files):\n",
    "        st.warning(\"The number of BF and PL images does not match. Only matching pairs will be processed.\")\n",
    "\n",
    "    for bf, pl in zip(bf_files, pl_files):\n",
    "        st.write(f\"Processing: {bf.name} and {pl.name}\")\n",
    "\n",
    "# Output Directory\n",
    "output_dir = \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load scale settings\n",
    "@st.cache_data\n",
    "def load_scale_settings():\n",
    "    try:\n",
    "        with open('scale_map.json', 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {\"40\": 5.64, \"100\": 13.89}\n",
    "\n",
    "um_to_px_map = load_scale_settings()\n",
    "\n",
    "# Sidebar Scale Input\n",
    "st.sidebar.header(\"Scale Settings\")\n",
    "selected_um = st.sidebar.selectbox(\"Known Distance (¬µm):\", list(um_to_px_map.keys()))\n",
    "distance_in_px = st.sidebar.text_input(\"Distance in Pixels:\", value=str(um_to_px_map.get(selected_um, \"\")))\n",
    "\n",
    "# Convert to float with error handling\n",
    "try:\n",
    "    s_um = float(selected_um)\n",
    "    d_px = float(distance_in_px)\n",
    "    PIXEL_TO_UM = 1 / (s_um / d_px)\n",
    "    st.success(f\"Calibration result: 1 px = {PIXEL_TO_UM:.4f} ¬µm\")\n",
    "    st.session_state.pixel_to_um = PIXEL_TO_UM\n",
    "except ValueError:\n",
    "    st.error(\"Please enter valid numeric values for scale calibration.\")\n",
    "\n",
    "# Add Scale Section\n",
    "st.sidebar.markdown(\"---\")\n",
    "st.sidebar.subheader(\"Manage Scale Settings\")\n",
    "\n",
    "new_um = st.sidebar.text_input(\"New ¬µm value\")\n",
    "new_px = st.sidebar.text_input(\"New pixel value\")\n",
    "if st.sidebar.button(\"‚ûï Add Scale\"):\n",
    "    try:\n",
    "        new_um_f = float(new_um)\n",
    "        new_px_f = float(new_px)\n",
    "        um_to_px_map[str(int(new_um_f))] = new_px_f\n",
    "        with open('scale_map.json', 'w') as f:\n",
    "            json.dump(um_to_px_map, f, indent=4)\n",
    "        st.sidebar.success(f\"Added scale: {int(new_um_f)} ¬µm = {new_px_f} px\")\n",
    "        st.cache_data.clear()\n",
    "        # Toggle rerun_flag to trigger rerun\n",
    "        st.session_state.rerun_flag = not st.session_state.rerun_flag\n",
    "    except ValueError:\n",
    "        st.sidebar.error(\"Enter valid numbers to add scale.\")\n",
    "\n",
    "# Delete Scale Option\n",
    "delete_um = st.sidebar.selectbox(\"Select ¬µm to delete\", list(um_to_px_map.keys()))\n",
    "if st.sidebar.button(\"üóëÔ∏è Delete Scale\"):\n",
    "    try:\n",
    "        um_to_px_map.pop(delete_um, None)\n",
    "        with open('scale_map.json', 'w') as f:\n",
    "            json.dump(um_to_px_map, f, indent=4)\n",
    "        st.sidebar.success(f\"Deleted scale: {delete_um} ¬µm\")\n",
    "        st.cache_data.clear()\n",
    "        # Toggle rerun_flag to trigger rerun\n",
    "        st.session_state.rerun_flag = not st.session_state.rerun_flag\n",
    "    except Exception as e:\n",
    "        st.sidebar.error(f\"Error deleting: {e}\")\n",
    "\n",
    "# Session State Initialization\n",
    "if \"script1_done\" not in st.session_state:\n",
    "    st.session_state.script1_done = False\n",
    "if \"script1_results\" not in st.session_state:\n",
    "    st.session_state.script1_results = []\n",
    "if \"zip_path_1\" not in st.session_state:\n",
    "    st.session_state.zip_path_1 = None\n",
    "\n",
    "# Start Button\n",
    "if st.button(\"Number of cells with crystals\"):\n",
    "    if not bf_files or not pl_files:\n",
    "        st.warning(\"Please upload both BF and PL files.\")\n",
    "    elif len(bf_files) != len(pl_files):\n",
    "        st.error(\"Mismatch in number of BF and PL files.\")\n",
    "    else:\n",
    "        st.session_state.script1_done = True\n",
    "        st.session_state.script1_results.clear()\n",
    "\n",
    "# Processing Logic\n",
    "if st.session_state.script1_done:\n",
    "    st.write(\"üîÑ Starting batch processing...\")\n",
    "    all_output_files = []\n",
    "\n",
    "    for bf_file, pl_file in zip(bf_files, pl_files):\n",
    "        #bf_file.seek(0)\n",
    "        #pl_file.seek(0)\n",
    "        \n",
    "        with tempfile.NamedTemporaryFile(delete=False) as bf_temp, tempfile.NamedTemporaryFile(delete=False) as pl_temp:\n",
    "            bf_temp.write(bf_file.read())\n",
    "            pl_temp.write(pl_file.read())\n",
    "            bf_path = bf_temp.name\n",
    "            pl_path = pl_temp.name\n",
    "        \n",
    "        imageA = cv2.imread(bf_path)\n",
    "        imageB = cv2.imread(pl_path)\n",
    "\n",
    "        if imageA is None or imageB is None:\n",
    "            st.warning(f\"Unable to read {bf_file.name} or {pl_file.name}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        grayA = rgb2gray(imageA)\n",
    "        grayA = exposure.equalize_adapthist(grayA)\n",
    "        grayA = cv2.bilateralFilter((grayA * 255).astype(np.uint8), 9, 75, 75)\n",
    "        threshold = threshold_otsu(grayA)\n",
    "        binary_A = (grayA < threshold).astype(np.uint8) * 255\n",
    "\n",
    "        # Apply morphological operations to clean up the binary mask\n",
    "        binary_A = morphology.opening(binary_A)\n",
    "        binary_A = morphology.remove_small_objects(binary_A.astype(bool), min_size=500)\n",
    "        binary_A = morphology.dilation(binary_A, morphology.disk(4))\n",
    "        binary_A = morphology.remove_small_holes(binary_A, area_threshold=5000)\n",
    "        binary_A = morphology.closing(binary_A, morphology.disk(4))\n",
    "        binary_A = (binary_A > 0).astype(np.uint8) * 255\n",
    "\n",
    "        region_labels_A = label(binary_A)\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        new_label_img = np.zeros_like(region_labels_A, dtype=np.int32)\n",
    "        label_counter = 1\n",
    "        #<1500,>=3,=2,=5,=42\n",
    "\n",
    "        # Compute average threshold based on the mean and standart desviation of region area\n",
    "        #max_area = max([region.area for region in region_props_A])\n",
    "        areas = [region.area for region in region_props_A]\n",
    "\n",
    "        mean_area = np.mean(areas)\n",
    "        median_area = np.median(areas)\n",
    "        std_area = np.std(areas)\n",
    "        min_area = np.min(areas)\n",
    "            \n",
    "        average = median_area + std_area \n",
    "\n",
    "        # Histogram Areas\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(areas, bins=20, color='skyblue', edgecolor='black')\n",
    "        hist_path_Areas = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_Areas.png\")\n",
    "        fig.savefig(hist_path_Areas)\n",
    "        all_output_files.append(hist_path_Areas)\n",
    "        \n",
    "        for region in region_props_A:\n",
    "            if region.area < average:\n",
    "                new_label_img[region.slice][region.image] = label_counter\n",
    "                label_counter += 1\n",
    "            else:\n",
    "                # Extract the subregion\n",
    "                region_mask = np.zeros_like(region_labels_A, dtype=np.uint8)\n",
    "                 region_mask[region.slice][region.image] = 1\n",
    "\n",
    "                # Compute distance transform\n",
    "                distance = ndi.distance_transform_edt(region_mask)\n",
    "\n",
    "                # Detect peaks for watershed markers\n",
    "                # Get coordinates\n",
    "                coordinates = peak_local_max(distance, labels=region_mask, min_distance=5)\n",
    "\n",
    "                # Create empty mask and mark coordinates\n",
    "                local_maxi = np.zeros_like(distance, dtype=bool)\n",
    "                local_maxi[tuple(coordinates.T)] = True\n",
    "\n",
    "                markers = label(local_maxi)\n",
    "\n",
    "                # Apply watershed on the distance transform\n",
    "                labels_ws = watershed(-distance, markers, mask=region_mask)\n",
    "\n",
    "                # Add the new labels to the global label image\n",
    "                for ws_label in np.unique(labels_ws):\n",
    "                    if ws_label == 0:\n",
    "                        continue\n",
    "                    mask = labels_ws == ws_label\n",
    "                    new_label_img[mask] = label_counter\n",
    "                    label_counter += 1\n",
    "\n",
    "        region_labels_A = new_label_img\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        # Ensure binary_A is the correct shape (resize if necessary)\n",
    "        if binary_A.shape != grayA.shape:\n",
    "            binary_A = resize(binary_A, grayA.shape, order=0, preserve_range=True, anti_aliasing=False)\n",
    "\n",
    "        # Convert label image to RGB for annotation\n",
    "        overlay_image = cv2.cvtColor((binary_A > 0).astype(np.uint8) * 255, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Loop through each region and annotate label number\n",
    "        for region in regionprops(region_labels_A):\n",
    "            y, x = region.centroid  # Note: (row, col) = (y, x)\n",
    "            label_id = region.label\n",
    "            cv2.putText(\n",
    "                overlay_image,\n",
    "                str(label_id),\n",
    "                (int(x), int(y)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),  # Red color for text\n",
    "                1,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "        # Save the annotated image\n",
    "        annotated_path = os.path.join(output_dir, f\"{bf_file.name}_Segmented_Cells.png\")\n",
    "        cv2.imwrite(annotated_path, overlay_image)\n",
    "        all_output_files.append(annotated_path)\n",
    "\n",
    "\n",
    "        region_area_df = pd.DataFrame({\n",
    "            \"Region_Label\": [r.label for r in region_props_A],\n",
    "            \"Region_Area (pixels)\": [r.area for r in region_props_A],\n",
    "            \"Region_Area (¬µm¬≤)\": [r.area * (PIXEL_TO_UM ** 2) for r in region_props_A]\n",
    "        })\n",
    "\n",
    "        region_area_df = region_area_df[region_area_df[\"Region_Area (¬µm¬≤)\"] > 0]\n",
    "        total_cells = region_area_df[\"Region_Label\"].count() - 1  # Subtract 1 if you're excluding the bottom-right region\n",
    "        region_area_df.loc[\"Total Area\"] = [\"\", \"Total Area\", region_area_df[\"Region_Area (¬µm¬≤)\"].sum()]\n",
    "        region_area_df.loc[\"Total Cells\"] = [\"\", \"Total Cells\", total_cells]\n",
    "\n",
    "        excel_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Region_Area.xlsx\")\n",
    "        region_area_df.to_excel(excel_path, index=False)\n",
    "\n",
    "        # Histogram A\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayA.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(threshold, color='red', linestyle='--')\n",
    "        hist_path_A = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_A.png\")\n",
    "        fig.savefig(hist_path_A)\n",
    "        all_output_files.append(hist_path_A)\n",
    "\n",
    "        # Image B thresholding\n",
    "        grayB = rgb2gray(imageB)\n",
    "        grayB = exposure.equalize_adapthist(grayB)\n",
    "        grayB = cv2.bilateralFilter((grayB * 255).astype(np.uint8), 9, 75, 75)\n",
    "        mean_intensity = np.mean(grayB)\n",
    "        std_intensity = np.std(grayB)\n",
    "        dynamic_threshold = mean_intensity + 4 * std_intensity\n",
    "        binary_B = (grayB > dynamic_threshold).astype(np.uint8)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayB.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(dynamic_threshold, color='red', linestyle='--')\n",
    "        hist_path_B = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_B.png\")\n",
    "        fig.savefig(hist_path_B)\n",
    "        all_output_files.append(hist_path_B)\n",
    "\n",
    "        overlap = (np.logical_and(cv2.resize(binary_A, (2048, 2048)) > 0, cv2.resize(binary_B, (2048, 2048)) > 0)).astype(np.uint8) * 255\n",
    "        overlap_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Overlap.png\")\n",
    "        cv2.imwrite(overlap_path, overlap)\n",
    "        all_output_files.append(overlap_path)\n",
    "\n",
    "        # Region associations\n",
    "        region_props = regionprops(label(overlap))\n",
    "        cell_props = region_props_A\n",
    "        crystal_to_cell = []\n",
    "        cell_to_crystals = defaultdict(list)\n",
    "\n",
    "        for region in region_props:\n",
    "            region_coords = set(map(tuple, region.coords))\n",
    "            best_match_cell = None\n",
    "            max_overlap = 0\n",
    "            for cell in cell_props:\n",
    "                cell_coords = set(map(tuple, cell.coords))\n",
    "                overlap_area = len(region_coords & cell_coords)\n",
    "                if overlap_area > 0:\n",
    "                    cell_to_crystals[cell.label].append(region.label)\n",
    "                if overlap_area > max_overlap:\n",
    "                    max_overlap = overlap_area\n",
    "                    best_match_cell = cell.label\n",
    "            crystal_to_cell.append({\n",
    "                \"Region_Label\": region.label,\n",
    "                \"Associated_Cell\": best_match_cell,\n",
    "                \"Overlap (pixels)\": max_overlap,\n",
    "                \"Region_Area (pixels)\": region.area,\n",
    "                \"Region_Area (¬µm¬≤)\": region.area * (PIXEL_TO_UM ** 2)\n",
    "            })\n",
    "\n",
    "            # ‚úÖ Store the crystal label for the matched cell\n",
    "            if best_match_cell is not None:\n",
    "                cell_to_crystals[best_match_cell].append(region.label)\n",
    "\n",
    "        df_mapping = pd.DataFrame(crystal_to_cell)\n",
    "        df_mapping = df_mapping[(df_mapping[\"Region_Area (¬µm¬≤)\"] < 10) & (df_mapping[\"Overlap (pixels)\"] > 0)]\n",
    "        df_mapping[\"Associated_Cell_Count\"] = df_mapping[\"Associated_Cell\"].map(df_mapping[\"Associated_Cell\"].value_counts())\n",
    "        df_mapping[\"Total_Cells_with_crystals\"] = df_mapping[\"Associated_Cell\"].nunique()\n",
    "        df_mapping.loc[\"Total\"] = [\"\", \"\", \"\", \"Total Area Crystals\", df_mapping[\"Region_Area (¬µm¬≤)\"].sum(), \"\", \"\"]\n",
    "\n",
    "        #cell_crystal_df = pd.DataFrame([\n",
    "        #    {\"Cell_Label\": k, \"Crystal_Labels\": \", \".join(map(str, v)), \"Crystal_Count\": len(v)}\n",
    "        #    for k, v in cell_to_crystals.items()\n",
    "        #])\n",
    "\n",
    "        # --- Optional: Save cell-to-crystal list (for debugging or export) ---\n",
    "        cell_crystal_df = pd.DataFrame([\n",
    "            {\n",
    "                \"Cell_Label\": cell_label,\n",
    "                #\"Crystal_Labels\": \", \".join(map(str, crystals)),\n",
    "                #\"Crystal_Count\": len(crystals)\n",
    "                \"Crystal_Labels\": \", \".join(map(str, set(crystals))),  # remove duplicates\n",
    "                \"Crystal_Count\": len(set(crystals))                    # correct count\n",
    "            }\n",
    "            for cell_label, crystals in cell_to_crystals.items()\n",
    "        ])\n",
    "        \n",
    "        merged_df = df_mapping.merge(region_area_df, left_on=\"Associated_Cell\", right_on=\"Region_Label\", how=\"inner\")\n",
    "\n",
    "        grouped_xlsx_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_All_Datasets.xlsx\")\n",
    "        with pd.ExcelWriter(grouped_xlsx_path, engine=\"xlsxwriter\") as writer:\n",
    "            region_area_df.to_excel(writer, sheet_name=\"Cells\", index=False)\n",
    "            df_mapping.to_excel(writer, sheet_name=\"Crystals\", index=False)\n",
    "            merged_df.to_excel(writer, sheet_name=\"Cells + Crystals\", index=False)\n",
    "            cell_crystal_df.to_excel(writer, sheet_name=\"Cell-Crystal Map\", index=False)\n",
    "\n",
    "        # Annotated Image\n",
    "        annotated_image = cv2.cvtColor(imageA, cv2.COLOR_GRAY2BGR) if imageA.ndim == 2 else imageA.copy()\n",
    "        for _, mapping in df_mapping.iterrows():\n",
    "            if pd.notna(mapping[\"Associated_Cell\"]):\n",
    "                region = next((r for r in region_props if r.label == mapping[\"Region_Label\"]), None)\n",
    "                if region:\n",
    "                    min_row, min_col, max_row, max_col = region.bbox\n",
    "                    cv2.rectangle(annotated_image, (min_col, min_row), (max_col, max_row), (0, 255, 0), 2)\n",
    "                    cv2.putText(annotated_image, f\"Cell {int(mapping['Associated_Cell'])}\", (min_col, max(min_row - 5, 10)),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "        annotated_image_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Annotated.png\")\n",
    "        cv2.imwrite(annotated_image_path, annotated_image)\n",
    "        all_output_files.append(annotated_image_path)\n",
    "\n",
    "        # Save session result\n",
    "        st.session_state.script1_results.append({\n",
    "            \"bf_name\": bf_file.name,\n",
    "            \"excel_path\": grouped_xlsx_path,\n",
    "            \"annotated_img_path\": annotated_image_path,\n",
    "            \"overlap_path\": overlap_path,\n",
    "            \"hist_A_path\": hist_path_A,\n",
    "            \"hist_B_path\": hist_path_B,\n",
    "        })\n",
    "\n",
    "    # Create ZIP\n",
    "    zip_path_1 = os.path.join(output_dir, \"All_Images_histograms.zip\")\n",
    "    with zipfile.ZipFile(zip_path_1, 'w') as zipf_1:\n",
    "        for file_path in all_output_files:\n",
    "            zipf_1.write(file_path, arcname=os.path.basename(file_path))\n",
    "    st.session_state.zip_path_1 = zip_path_1\n",
    "    st.success(\"‚úÖ Processing complete!\")\n",
    "\n",
    "# Display Outputs and Download Buttons\n",
    "if st.session_state.script1_results:\n",
    "    st.header(\"üì¶ Results\")\n",
    "\n",
    "    for result1 in st.session_state.script1_results:\n",
    "        st.subheader(f\"üìÅ {result1['bf_name']}\")\n",
    "        st.image(result1[\"annotated_img_path\"], caption=\"Detections crystals\")\n",
    "        st.image(result1[\"overlap_path\"], caption=\"Correlation\")\n",
    "\n",
    "        with open(result1[\"excel_path\"], \"rb\") as f1:\n",
    "            st.download_button(\"üìä Download Dataset\", f1, file_name=os.path.basename(result1[\"excel_path\"]),key=f\"download_button_{os.path.basename(result1['excel_path'])}\")\n",
    "            \n",
    "    with open(st.session_state.zip_path_1, \"rb\") as zf_1:\n",
    "        st.download_button(\"üóÇÔ∏è Download All Images and Histograms\", zf_1, file_name=\"All_Images_histograms.zip\")\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Session State Initialization\n",
    "if \"script2_done\" not in st.session_state:\n",
    "    st.session_state.script2_done = False\n",
    "if \"script2_results\" not in st.session_state:\n",
    "    st.session_state.script2_results = []\n",
    "if \"zip_path_2\" not in st.session_state:\n",
    "    st.session_state.zip_path_2 = None\n",
    "\n",
    "# Start Button\n",
    "if st.button(\"Areas\"):\n",
    "    if not bf_files or not pl_files:\n",
    "        st.warning(\"Please upload both BF and PL files.\")\n",
    "    elif len(bf_files) != len(pl_files):\n",
    "        st.error(\"Mismatch in number of BF and PL files.\")\n",
    "    else:\n",
    "        st.session_state.script2_done = True\n",
    "        st.session_state.script2_results.clear()\n",
    "\n",
    "# Processing Logic\n",
    "if st.session_state.script2_done:\n",
    "    st.write(\"üîÑ Starting batch processing...\")\n",
    "    all_output_files = []\n",
    "\n",
    "    for bf_file, pl_file in zip(bf_files, pl_files):\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as bf_temp, tempfile.NamedTemporaryFile(delete=False) as pl_temp:\n",
    "            bf_temp.write(bf_file.read())\n",
    "            pl_temp.write(pl_file.read())\n",
    "            bf_path = bf_temp.name\n",
    "            pl_path = pl_temp.name\n",
    "\n",
    "        imageA = cv2.imread(bf_path)\n",
    "        imageB = cv2.imread(pl_path)\n",
    "\n",
    "        if imageA is None or imageB is None:\n",
    "            st.warning(f\"Unable to read {bf_file.name} or {pl_file.name}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        grayA = rgb2gray(imageA)\n",
    "        grayA = exposure.equalize_adapthist(grayA)\n",
    "        grayA = cv2.bilateralFilter((grayA * 255).astype(np.uint8), 9, 75, 75)\n",
    "        threshold = threshold_otsu(grayA)\n",
    "        binary_A = (grayA < threshold).astype(np.uint8) * 255\n",
    "\n",
    "        # Apply morphological operations to clean up the binary mask\n",
    "        binary_A = morphology.opening(binary_A)\n",
    "        binary_A = morphology.remove_small_objects(binary_A.astype(bool), min_size=500)\n",
    "        binary_A = morphology.dilation(binary_A, morphology.disk(4))\n",
    "        binary_A = morphology.remove_small_holes(binary_A, area_threshold=5000)\n",
    "        binary_A = morphology.closing(binary_A, morphology.disk(4))\n",
    "        binary_A = (binary_A > 0).astype(np.uint8) * 255\n",
    "\n",
    "        region_labels_A = label(binary_A)\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        new_label_img = np.zeros_like(region_labels_A, dtype=np.int32)\n",
    "        label_counter = 1\n",
    "        #<1500,>=3,=2,=5,=42\n",
    "\n",
    "        # Compute average threshold based on the mean and standart desviation of region area\n",
    "        #max_area = max([region.area for region in region_props_A])\n",
    "        areas = [region.area for region in region_props_A]\n",
    "\n",
    "        mean_area = np.mean(areas)\n",
    "        median_area = np.median(areas)\n",
    "        std_area = np.std(areas)\n",
    "        min_area = np.min(areas)\n",
    "            \n",
    "        average = median_area + std_area \n",
    "\n",
    "        # Histogram Areas\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(areas, bins=20, color='skyblue', edgecolor='black')\n",
    "        hist_path_Areas = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_Areas.png\")\n",
    "        fig.savefig(hist_path_Areas)\n",
    "        all_output_files.append(hist_path_Areas)\n",
    "        \n",
    "        for region in region_props_A:\n",
    "            if region.area < average:\n",
    "                new_label_img[region.slice][region.image] = label_counter\n",
    "                label_counter += 1\n",
    "            else:\n",
    "                # Extract the subregion\n",
    "                region_mask = np.zeros_like(region_labels_A, dtype=np.uint8)\n",
    "                region_mask[region.slice][region.image] = 1\n",
    "\n",
    "                # Compute distance transform\n",
    "                distance = ndi.distance_transform_edt(region_mask)\n",
    "\n",
    "                # Detect peaks for watershed markers\n",
    "                # Get coordinates\n",
    "                coordinates = peak_local_max(distance, labels=region_mask, min_distance=5)\n",
    "\n",
    "                # Create empty mask and mark coordinates\n",
    "                local_maxi = np.zeros_like(distance, dtype=bool)\n",
    "                local_maxi[tuple(coordinates.T)] = True\n",
    "\n",
    "                markers = label(local_maxi)\n",
    "\n",
    "                # Apply watershed on the distance transform\n",
    "                labels_ws = watershed(-distance, markers, mask=region_mask)\n",
    "\n",
    "                # Add the new labels to the global label image\n",
    "                for ws_label in np.unique(labels_ws):\n",
    "                    if ws_label == 0:\n",
    "                        continue\n",
    "                    mask = labels_ws == ws_label\n",
    "                    new_label_img[mask] = label_counter\n",
    "                    label_counter += 1\n",
    "\n",
    "        region_labels_A = new_label_img\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        # Ensure binary_A is the correct shape (resize if necessary)\n",
    "        if binary_A.shape != grayA.shape:\n",
    "            binary_A = resize(binary_A, grayA.shape, order=0, preserve_range=True, anti_aliasing=False)\n",
    "\n",
    "        # Convert label image to RGB for annotation\n",
    "        overlay_image = cv2.cvtColor((binary_A > 0).astype(np.uint8) * 255, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Loop through each region and annotate label number\n",
    "        for region in regionprops(region_labels_A):\n",
    "            y, x = region.centroid  # Note: (row, col) = (y, x)\n",
    "            label_id = region.label\n",
    "            cv2.putText(\n",
    "                overlay_image,\n",
    "                str(label_id),\n",
    "                (int(x), int(y)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),  # Red color for text\n",
    "                1,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "        # Save the annotated image\n",
    "        annotated_path = os.path.join(output_dir, f\"{bf_file.name}_Segmented_Cells.png\")\n",
    "        cv2.imwrite(annotated_path, overlay_image)\n",
    "        all_output_files.append(annotated_path)\n",
    "\n",
    "        region_area_df = pd.DataFrame({\n",
    "            \"Region_Label\": [r.label for r in region_props_A],\n",
    "            \"Region_Area (pixels)\": [r.area for r in region_props_A],\n",
    "            \"Region_Area (¬µm¬≤)\": [r.area * (PIXEL_TO_UM ** 2) for r in region_props_A]\n",
    "        })\n",
    "\n",
    "        region_area_df = region_area_df[region_area_df[\"Region_Area (¬µm¬≤)\"] > 0]\n",
    "        total_cells = region_area_df[\"Region_Label\"].count() - 1  # Subtract 1 if you're excluding the bottom-right region\n",
    "        region_area_df.loc[\"Total Area\"] = [\"\", \"Total Area\", region_area_df[\"Region_Area (¬µm¬≤)\"].sum()]\n",
    "        region_area_df.loc[\"Total Cells\"] = [\"\", \"Total Cells\", total_cells]\n",
    "\n",
    "        excel_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Region_Area.xlsx\")\n",
    "        region_area_df.to_excel(excel_path, index=False)\n",
    "\n",
    "        # Histogram A\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayA.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(threshold, color='red', linestyle='--')\n",
    "        hist_path_A = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_A.png\")\n",
    "        fig.savefig(hist_path_A)\n",
    "        all_output_files.append(hist_path_A)\n",
    "\n",
    "        # Image B thresholding\n",
    "        grayB = rgb2gray(imageB)\n",
    "        grayB = exposure.equalize_adapthist(grayB)\n",
    "        grayB = cv2.bilateralFilter((grayB * 255).astype(np.uint8), 9, 75, 75)\n",
    "        mean_intensity = np.mean(grayB)\n",
    "        std_intensity = np.std(grayB)\n",
    "        dynamic_threshold = mean_intensity + 4.6 * std_intensity\n",
    "        binary_B = (grayB > dynamic_threshold).astype(np.uint8)\n",
    "\n",
    "        binary_B = opening(binary_B)# Remove small noise\n",
    "        #binary_B= morphology.dilation(binary_B, morphology.disk(4)) # Dilation\n",
    "        #binary_B = morphology.closing(binary_B, morphology.disk(4)) # Closing\n",
    "        binary_B = (binary_B > 0).astype(np.uint8) * 255 # Convert back to binary\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayB.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(dynamic_threshold, color='red', linestyle='--')\n",
    "        hist_path_B = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_B.png\")\n",
    "        fig.savefig(hist_path_B)\n",
    "        all_output_files.append(hist_path_B)\n",
    "\n",
    "        overlap = (np.logical_and(cv2.resize(binary_A, (2048, 2048)) > 0, cv2.resize(binary_B, (2048, 2048)) > 0)).astype(np.uint8) * 255\n",
    "        overlap_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Overlap.png\")\n",
    "        cv2.imwrite(overlap_path, overlap)\n",
    "        all_output_files.append(overlap_path)\n",
    "\n",
    "        # Region associations\n",
    "        region_props = regionprops(label(overlap))\n",
    "        cell_props = region_props_A\n",
    "        crystal_to_cell = []\n",
    "        cell_to_crystals = defaultdict(list)\n",
    "\n",
    "        for region in region_props:\n",
    "            region_coords = set(map(tuple, region.coords))\n",
    "            best_match = None\n",
    "            max_overlap = 0\n",
    "            for cell in cell_props:\n",
    "                cell_coords = set(map(tuple, cell.coords))\n",
    "                overlap_area = len(region_coords & cell_coords)\n",
    "                if overlap_area > 0:\n",
    "                    cell_to_crystals[cell.label].append(region.label)\n",
    "                if overlap_area > max_overlap:\n",
    "                    max_overlap = overlap_area\n",
    "                    best_match_cell = cell.label\n",
    "            crystal_to_cell.append({\n",
    "                \"Region_Label\": region.label,\n",
    "                \"Associated_Cell\": best_match_cell,\n",
    "                \"Overlap (pixels)\": max_overlap,\n",
    "                \"Region_Area (pixels)\": region.area,\n",
    "                \"Region_Area (¬µm¬≤)\": region.area * (PIXEL_TO_UM ** 2)\n",
    "            })\n",
    "\n",
    "            # ‚úÖ Store the crystal label for the matched cell\n",
    "            if best_match_cell is not None:\n",
    "                cell_to_crystals[best_match_cell].append(region.label)\n",
    "\n",
    "        df_mapping = pd.DataFrame(crystal_to_cell)\n",
    "        df_mapping = df_mapping[(df_mapping[\"Region_Area (¬µm¬≤)\"] < 6) & (df_mapping[\"Overlap (pixels)\"] > 0)]\n",
    "        df_mapping[\"Associated_Cell_Count\"] = df_mapping[\"Associated_Cell\"].map(df_mapping[\"Associated_Cell\"].value_counts())\n",
    "        df_mapping[\"Total_Cells_with_crystals\"] = df_mapping[\"Associated_Cell\"].nunique()\n",
    "        df_mapping.loc[\"Total\"] = [\"\", \"\", \"\", \"Total Area Crystals\", df_mapping[\"Region_Area (¬µm¬≤)\"].sum(), \"\", \"\"]\n",
    "\n",
    "        #cell_crystal_df = pd.DataFrame([\n",
    "        #    {\"Cell_Label\": k, \"Crystal_Labels\": \", \".join(map(str, v)), \"Crystal_Count\": len(v)}\n",
    "        #    for k, v in cell_to_crystals.items()\n",
    "        #])\n",
    "\n",
    "        # --- Optional: Save cell-to-crystal list (for debugging or export) ---\n",
    "        cell_crystal_df = pd.DataFrame([\n",
    "            {\n",
    "                \"Cell_Label\": cell_label,\n",
    "                #\"Crystal_Labels\": \", \".join(map(str, crystals)),\n",
    "                #\"Crystal_Count\": len(crystals)\n",
    "                \"Crystal_Labels\": \", \".join(map(str, set(crystals))),  # remove duplicates\n",
    "                \"Crystal_Count\": len(set(crystals))                    # correct count\n",
    "            }\n",
    "            for cell_label, crystals in cell_to_crystals.items()\n",
    "        ])\n",
    "        \n",
    "        merged_df = df_mapping.merge(region_area_df, left_on=\"Associated_Cell\", right_on=\"Region_Label\", how=\"inner\")\n",
    "\n",
    "        #-----------------------------------------------------------------------------------------\n",
    "        # Initialize the column with NaNs\n",
    "        merged_df[\"Crystal/Cell Area (%)\"] = pd.NA\n",
    "\n",
    "        # Calculate percentage only for rows except the last two\n",
    "        merged_df.loc[:-3, \"Crystal/Cell Area (%)\"] = (\n",
    "            merged_df.loc[:-3, \"Region_Area (¬µm¬≤)_x\"] / merged_df.loc[:-3, \"Region_Area (¬µm¬≤)_y\"] * 100\n",
    "        )\n",
    "        #-------------------------------------------\n",
    "\n",
    "        grouped_xlsx_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_All_Datasets.xlsx\")\n",
    "        with pd.ExcelWriter(grouped_xlsx_path, engine=\"xlsxwriter\") as writer:\n",
    "            region_area_df.to_excel(writer, sheet_name=\"Cells\", index=False)\n",
    "            df_mapping.to_excel(writer, sheet_name=\"Crystals\", index=False)\n",
    "            merged_df.to_excel(writer, sheet_name=\"Cells + Crystals\", index=False)\n",
    "            cell_crystal_df.to_excel(writer, sheet_name=\"Cell-Crystal Map\", index=False)\n",
    "\n",
    "        # Annotated Image\n",
    "        annotated_image = cv2.cvtColor(imageA, cv2.COLOR_GRAY2BGR) if imageA.ndim == 2 else imageA.copy()\n",
    "        for _, mapping in df_mapping.iterrows():\n",
    "            if pd.notna(mapping[\"Associated_Cell\"]):\n",
    "                region = next((r for r in region_props if r.label == mapping[\"Region_Label\"]), None)\n",
    "                if region:\n",
    "                    min_row, min_col, max_row, max_col = region.bbox\n",
    "                    cv2.rectangle(annotated_image, (min_col, min_row), (max_col, max_row), (0, 255, 0), 2)\n",
    "                    cv2.putText(annotated_image, f\"Cell {int(mapping['Associated_Cell'])}\", (min_col, max(min_row - 5, 10)),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "        annotated_image_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Annotated.png\")\n",
    "        cv2.imwrite(annotated_image_path, annotated_image)\n",
    "        all_output_files.append(annotated_image_path)\n",
    "\n",
    "        # Save session result\n",
    "        st.session_state.script2_results.append({\n",
    "            \"bf_name\": bf_file.name,\n",
    "            \"excel_path\": grouped_xlsx_path,\n",
    "            \"annotated_img_path\": annotated_image_path,\n",
    "            \"overlap_path\": overlap_path,\n",
    "            \"hist_A_path\": hist_path_A,\n",
    "            \"hist_B_path\": hist_path_B,\n",
    "        })\n",
    "\n",
    "    # Create ZIP\n",
    "    zip_path_2 = os.path.join(output_dir, \"All_Images_histograms.zip\")\n",
    "    with zipfile.ZipFile(zip_path_2, 'w') as zipf_2:\n",
    "        for file_path in all_output_files:\n",
    "            zipf_2.write(file_path, arcname=os.path.basename(file_path))\n",
    "    st.session_state.zip_path_2 = zip_path_2\n",
    "    st.success(\"‚úÖ Processing complete!\")\n",
    "\n",
    "# Display Outputs and Download Buttons\n",
    "if st.session_state.script2_results:\n",
    "    st.header(\"üì¶ Results\")\n",
    "\n",
    "    for result2 in st.session_state.script2_results:\n",
    "        st.subheader(f\"üìÅ {result2['bf_name']}\")\n",
    "        st.image(result2[\"annotated_img_path\"], caption=\"Detection crystals\")\n",
    "        st.image(result2[\"overlap_path\"], caption=\"Correlation\")\n",
    "\n",
    "        with open(result2[\"excel_path\"], \"rb\") as f2:\n",
    "            st.download_button(\"üìä Download Dataset\", f2, file_name=os.path.basename(result2[\"excel_path\"]),key=f\"download_button_{os.path.basename(result2['excel_path'])}\")\n",
    "\n",
    "    with open(st.session_state.zip_path_2, \"rb\") as zf_2:\n",
    "        st.download_button(\"üóÇÔ∏è Download All Images and Histograms\", zf_2, file_name=\"All_Images_histograms.zip\")\n",
    "\n",
    "# Session State Initialization\n",
    "if \"script3_done\" not in st.session_state:\n",
    "    st.session_state.script3_done = False\n",
    "if \"script3_results\" not in st.session_state:\n",
    "    st.session_state.script3_results = []\n",
    "if \"zip_path_3\" not in st.session_state:\n",
    "    st.session_state.zip_path_3 = None\n",
    "\n",
    "# Start Button\n",
    "if st.button(\"Number of cells\"):\n",
    "    if not bf_files or not pl_files:\n",
    "        st.warning(\"Please upload both BF and PL files.\")\n",
    "    elif len(bf_files) != len(pl_files):\n",
    "        st.error(\"Mismatch in number of BF and PL files.\")\n",
    "    else:\n",
    "        st.session_state.script3_done = True\n",
    "        st.session_state.script3_results.clear()\n",
    "\n",
    "# Processing Logic\n",
    "if st.session_state.script3_done:\n",
    "    st.write(\"üîÑ Starting batch processing...\")\n",
    "    all_output_files = []\n",
    "\n",
    "    for bf_file, pl_file in zip(bf_files, pl_files):\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as bf_temp, tempfile.NamedTemporaryFile(delete=False) as pl_temp:\n",
    "            bf_temp.write(bf_file.read())\n",
    "            pl_temp.write(pl_file.read())\n",
    "            bf_path = bf_temp.name\n",
    "            pl_path = pl_temp.name\n",
    "\n",
    "        imageA = cv2.imread(bf_path)\n",
    "        imageB = cv2.imread(pl_path)\n",
    "\n",
    "        if imageA is None or imageB is None:\n",
    "            st.warning(f\"Unable to read {bf_file.name} or {pl_file.name}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Convert BF image to grayscale and enhance contrast\n",
    "        grayA = rgb2gray(imageA)\n",
    "\n",
    "        # ----- CROP SCALE BAR REGION (e.g., bottom-right %) -----\n",
    "        h, w = grayA.shape\n",
    "        crop_margin_h = int(0.015* h)  # % of height-0.01\n",
    "        crop_margin_w = int(0.025 * w)  # % of width-0.02\n",
    "\n",
    "        # Create a mask that excludes bottom-right corner\n",
    "        mask = np.ones_like(grayA, dtype=bool)\n",
    "        mask[h - crop_margin_h:, w - crop_margin_w:] = False\n",
    "        grayA = grayA * mask  # Set scale bar region to 0\n",
    "        \n",
    "        # Adaptive histogram equalization\n",
    "        grayA = exposure.equalize_adapthist(grayA)\n",
    "        # Noise reduction\n",
    "        grayA = cv2.bilateralFilter((grayA * 255).astype(np.uint8), 9, 75, 75)\n",
    "        # Compute threshold using Li's method\n",
    "        threshold = threshold_otsu(grayA)\n",
    "        # Apply thresholding\n",
    "        binary_A = (grayA < threshold).astype(np.uint8) * 255\n",
    "    \n",
    "        # Apply morphological operations to clean up the binary mask\n",
    "        binary_A = morphology.opening(binary_A)\n",
    "        binary_A = morphology.remove_small_objects(binary_A.astype(bool), min_size=500)\n",
    "        binary_A = morphology.dilation(binary_A, morphology.disk(4))\n",
    "        binary_A = morphology.remove_small_holes(binary_A, area_threshold=5000)\n",
    "        binary_A = morphology.closing(binary_A, morphology.disk(4))\n",
    "        binary_A = (binary_A > 0).astype(np.uint8) * 255\n",
    "    \n",
    "        # Define crop box coordinates (bottom-right crop region)\n",
    "        crop_start_row = h - crop_margin_h\n",
    "        crop_start_col = w - crop_margin_w\n",
    "\n",
    "        filtered_labels = []\n",
    "\n",
    "        # Create a mask for the crop area pixels\n",
    "        crop_mask = np.zeros_like(region_labels_A, dtype=bool)\n",
    "        crop_mask[crop_start_row:, crop_start_col:] = True\n",
    "\n",
    "        for region in region_props_A:\n",
    "            # Get the mask of this region (boolean)\n",
    "            region_mask = (region_labels_A == region.label)\n",
    "    \n",
    "            # Check if any pixel in this region overlaps with the crop mask\n",
    "            if np.any(region_mask & crop_mask):\n",
    "                # Region overlaps the crop area, skip it\n",
    "                continue\n",
    "    \n",
    "            filtered_labels.append(region.label)\n",
    "\n",
    "        # Create new labeled image excluding those regions\n",
    "        new_label_img = np.zeros_like(region_labels_A, dtype=np.int32)\n",
    "        label_counter = 1\n",
    "        for lbl in filtered_labels:\n",
    "            new_label_img[region_labels_A == lbl] = label_counter\n",
    "            label_counter += 1\n",
    "\n",
    "        region_labels_A[crop_start_row:, crop_start_col:] = 0\n",
    "\n",
    "        # Update region_labels_A and region_props_A to filtered versions\n",
    "        region_labels_A = new_label_img\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        # Compute average threshold based on the mean and standart desviation of region area\n",
    "        #max_area = max([region.area for region in region_props_A])\n",
    "        areas = [region.area for region in region_props_A]\n",
    "\n",
    "        #mean_area = np.mean(areas)\n",
    "        median_area = np.median(areas)\n",
    "        std_area = np.std(areas)\n",
    "        min_area = np.min(areas)\n",
    "            \n",
    "        average = median_area + std_area \n",
    "\n",
    "        # Histogram Areas\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(areas, bins=20, color='skyblue', edgecolor='black')\n",
    "        hist_path_Areas = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_Areas.png\")\n",
    "        fig.savefig(hist_path_Areas)\n",
    "        all_output_files.append(hist_path_Areas)\n",
    "        \n",
    "        for region in region_props_A:\n",
    "            if region.area < average:\n",
    "                new_label_img[region.slice][region.image] = label_counter\n",
    "                label_counter += 1\n",
    "            else:\n",
    "                # Extract the subregion\n",
    "                region_mask = np.zeros_like(region_labels_A, dtype=np.uint8)\n",
    "                region_mask[region.slice][region.image] = 1\n",
    "\n",
    "                # Compute distance transform\n",
    "                distance = ndi.distance_transform_edt(region_mask)\n",
    "\n",
    "                # Detect peaks for watershed markers\n",
    "                # Get coordinates\n",
    "                coordinates = peak_local_max(distance, labels=region_mask, min_distance=5)\n",
    "\n",
    "                # Create empty mask and mark coordinates\n",
    "                local_maxi = np.zeros_like(distance, dtype=bool)\n",
    "                local_maxi[tuple(coordinates.T)] = True\n",
    "\n",
    "                markers = label(local_maxi)\n",
    "\n",
    "                # Apply watershed on the distance transform\n",
    "                labels_ws = watershed(-distance, markers, mask=region_mask)\n",
    "\n",
    "                # Add the new labels to the global label image\n",
    "                for ws_label in np.unique(labels_ws):\n",
    "                    if ws_label == 0:\n",
    "                        continue\n",
    "                    mask = labels_ws == ws_label\n",
    "                    new_label_img[mask] = label_counter\n",
    "                    label_counter += 1\n",
    "\n",
    "        region_labels_A = new_label_img\n",
    "        region_props_A = regionprops(region_labels_A)\n",
    "\n",
    "        # Ensure binary_A is the correct shape (resize if necessary)\n",
    "        if binary_A.shape != grayA.shape:\n",
    "            binary_A = resize(binary_A, grayA.shape, order=0, preserve_range=True, anti_aliasing=False)\n",
    "\n",
    "        # Convert label image to RGB for annotation\n",
    "        overlay_image = cv2.cvtColor((binary_A > 0).astype(np.uint8) * 255, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Loop through each region and annotate label number\n",
    "        for region in regionprops(region_labels_A):\n",
    "            y, x = region.centroid  # Note: (row, col) = (y, x)\n",
    "            label_id = region.label\n",
    "            cv2.putText(\n",
    "                overlay_image,\n",
    "                str(label_id),\n",
    "                (int(x), int(y)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),  # Red color for text\n",
    "                1,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "        # Save the annotated image\n",
    "        annotated_path = os.path.join(output_dir, f\"{bf_file.name}_Segmented_Annotated.png\")\n",
    "        cv2.imwrite(annotated_path, overlay_image)\n",
    "        all_output_files.append(annotated_path)\n",
    "            \n",
    "        filtered_binary_A = np.zeros_like(binary_A)\n",
    "        for prop in region_props_A:\n",
    "            if prop.area > 0:\n",
    "                min_row, min_col, max_row, max_col = prop.bbox\n",
    "                filtered_binary_A[min_row:max_row, min_col:max_col] = (\n",
    "                    region_labels_A[min_row:max_row, min_col:max_col] == prop.label\n",
    "                )\n",
    "\n",
    "        filtered_binary_A = (filtered_binary_A > 0).astype(np.uint8) * 255\n",
    "\n",
    "        #px_per_um = um_to_px_map[selected_um]  # ¬µm per pixel\n",
    "\n",
    "        # Create a DataFrame for the regions with their area in ¬µm¬≤\n",
    "        region_area_df = pd.DataFrame({\n",
    "            \"Region_Label\": [region.label for region in region_props_A],\n",
    "            \"Region_Area (pixels)\": [region.area for region in region_props_A],\n",
    "            \"Region_Area (¬µm¬≤)\": [r.area * (PIXEL_TO_UM ** 2) for r in region_props_A]\n",
    "        })\n",
    "    \n",
    "        region_area_df = region_area_df[region_area_df[\"Region_Area (¬µm¬≤)\"] > 0]\n",
    "        total_cells = region_area_df[\"Region_Label\"].count() - 1  # Subtract 1 if you're excluding the bottom-right region\n",
    "        region_area_df.loc[\"Total Area\"] = [\"\", \"Total Area\", region_area_df[\"Region_Area (¬µm¬≤)\"].sum()]\n",
    "        region_area_df.loc[\"Total Cells\"] = [\"\", \"Total Cells\", total_cells]\n",
    "\n",
    "        excel_path = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Region_Area.xlsx\")\n",
    "        region_area_df.to_excel(excel_path, index=False)\n",
    "\n",
    "        # Histogram A\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(grayA.ravel(), bins=256, range=[0, 255])\n",
    "        ax.axvline(threshold, color='red', linestyle='--')\n",
    "        hist_path_A = os.path.join(output_dir, f\"{os.path.splitext(bf_file.name)[0]}_Histogram_A.png\")\n",
    "        fig.savefig(hist_path_A)\n",
    "        all_output_files.append(hist_path_A)\n",
    "\n",
    "        # Save session result\n",
    "        st.session_state.script3_results.append({\n",
    "            \"bf_name\": bf_file.name,\n",
    "            \"annotated_path\": annotated_path,\n",
    "            \"hist_A_path\": hist_path_A,\n",
    "            \"hist_path_Areas\": hist_path_Areas,\n",
    "            \"excel_path\": excel_path,\n",
    "        })\n",
    "\n",
    "    # Create ZIP\n",
    "    zip_path_3 = os.path.join(output_dir, \"All_Images_histograms.zip\")\n",
    "    with zipfile.ZipFile(zip_path_3, 'w') as zipf_3:\n",
    "        for file_path in all_output_files:\n",
    "            zipf_3.write(file_path, arcname=os.path.basename(file_path))\n",
    "    st.session_state.zip_path_3 = zip_path_3\n",
    "    st.success(\"‚úÖ Processing complete!\")\n",
    "\n",
    "# Display Outputs and Download Buttons\n",
    "if st.session_state.script3_results:\n",
    "    st.header(\"üì¶ Results\")\n",
    "\n",
    "    for result3 in st.session_state.script3_results:\n",
    "        st.subheader(f\"üìÅ {result3['bf_name']}\")\n",
    "        st.image(result3[\"annotated_path\"], caption=\"Segmented Image\")\n",
    "        st.image(result3[\"hist_path_Areas\"], caption=\"Areas Histogram\")\n",
    "        st.image(result3[\"hist_A_path\"], caption=\"Pixels Intensity Histogram\")\n",
    "\n",
    "        with open(result3[\"excel_path\"], \"rb\") as f3:\n",
    "            st.download_button(\"üìä Download Dataset\", f3, file_name=os.path.basename(result3[\"excel_path\"]),key=f\"download_button_{os.path.basename(result3['excel_path'])}\")\n",
    "\n",
    "    with open(st.session_state.zip_path_3, \"rb\") as zf_3:\n",
    "        st.download_button(\"üóÇÔ∏è Download All Images and Histograms\", zf_3, file_name=\"All_Images_histograms.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
