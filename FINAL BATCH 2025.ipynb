{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9111ab59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Import necessary libraries\n",
    "import os\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import morphology, exposure\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.morphology import opening, remove_small_objects, remove_small_holes\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage\n",
    "\n",
    "# Image scale: 7.0917 pixels = 1 µm\n",
    "pixel_to_um = 1 / 7.0917\n",
    "\n",
    "# Paths to the folders\n",
    "bf_folder = \"C:\\\\Users\\\\Admin\\\\Downloads\\\\research algue 2024\\\\dataframes\\\\BATCH\\\\Crystal development screen\\\\batch 13 consistent screen\\\\2025_01_07 10X chlamy screen\\\\BF\"\n",
    "pl_folder = \"C:\\\\Users\\\\Admin\\\\Downloads\\\\research algue 2024\\\\dataframes\\\\BATCH\\\\Crystal development screen\\\\batch 13 consistent screen\\\\2025_01_07 10X chlamy screen\\\\PL\"\n",
    "output_folder = \"C:\\\\Users\\\\Admin\\\\Downloads\\\\research algue 2024\\\\dataframes\\\\BATCH\\\\BATCH 13\\\\2025_1_7 10X chlamy screen\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# List all .tif files in the folders\n",
    "bf_files = sorted([f for f in os.listdir(bf_folder) if f.endswith('.tif')])\n",
    "pl_files = sorted([f for f in os.listdir(pl_folder) if f.endswith('.tif')])\n",
    "\n",
    "# Ensure there are matching files in both folders\n",
    "if len(bf_files) != len(pl_files):\n",
    "    raise ValueError(\"Mismatch in the number of BF and PL .tif files.\")\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# Batch process all matching .tif files\n",
    "for bf_file, pl_file in zip(bf_files, pl_files):\n",
    "    print(f\"Processing: {bf_file} and {pl_file}\")\n",
    "    \n",
    "    bf_image_path = os.path.join(bf_folder, bf_file)\n",
    "    pl_image_path = os.path.join(pl_folder, pl_file)\n",
    "\n",
    "    # Load the images\n",
    "    imageA = cv2.imread(bf_image_path)\n",
    "    imageB = cv2.imread(pl_image_path)\n",
    "\n",
    "    # Ensure the images are loaded properly\n",
    "    if imageA is None or imageB is None:\n",
    "        print(f\"Skipping {bf_file} or {pl_file}: Unable to load image.\")\n",
    "        continue\n",
    "\n",
    "    # Binary mask creation for Image A\n",
    "    grayA = rgb2gray(imageA)\n",
    "    #NEW-----------------------------------------------------------\n",
    "    grayA = exposure.equalize_adapthist(grayA)\n",
    "    grayA = cv2.bilateralFilter((grayA * 255).astype(np.uint8), 9, 75, 75)\n",
    "    mean_intensity = np.mean(grayA)\n",
    "    P1 = np.percentile(grayA, 10)\n",
    "    P2 = np.percentile(grayA, 15)\n",
    "    P3 = np.percentile(grayA, 20)\n",
    "    dynamic_threshold = P1 if mean_intensity < 100 else (P2 if mean_intensity < 200 else P3)\n",
    "    binary_A = (grayA < dynamic_threshold).astype(np.uint8)*255\n",
    "\n",
    "    #------------------------------------------\n",
    "    #dynamic_threshold = np.percentile(grayA,20)\n",
    "    #binary_A = (grayA < dynamic_threshold).astype(np.uint8) * 255\n",
    "    binary_A = opening(binary_A)\n",
    "    binary_A = remove_small_objects(binary_A.astype(bool), min_size=1000)\n",
    "    binary_A = remove_small_holes(binary_A, area_threshold=100000)\n",
    "    binary_A = morphology.dilation(binary_A, morphology.disk(3))\n",
    "    binary_A = morphology.closing(binary_A, morphology.disk(3))\n",
    "    binary_A = (binary_A > 0).astype(np.uint8) * 255\n",
    "    \n",
    "    # Find regions in binary_A and calculate their areas in µm²\n",
    "    region_labels_A = label(binary_A)\n",
    "    region_props_A = regionprops(region_labels_A)\n",
    "    \n",
    "    # Apply distance transform to the binary mask\n",
    "    distance = distance_transform_edt(binary_A)\n",
    "\n",
    "    # Find local maxima to use as markers\n",
    "    local_maxi = peak_local_max(distance, indices=False, labels=binary_A, min_distance=1)\n",
    "\n",
    "    # Label the local maxima\n",
    "    markers, _ = ndimage.label(local_maxi)\n",
    "\n",
    "    # Apply watershed\n",
    "    labels_watershed = watershed(-distance, markers, mask=binary_A)\n",
    "\n",
    "    # Visualization of watershed result\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(labels_watershed, cmap='nipy_spectral')\n",
    "    plt.title('Watershed Segmentation')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the segmented binary image\n",
    "    segmented_image_path = os.path.join(output_folder, f\"{os.path.splitext(bf_file)[0]}_Segmented.png\")\n",
    "    cv2.imwrite(segmented_image_path, labels_watershed)\n",
    "    print(f\"Saved segmented image for {bf_file} to {segmented_image_path}\")\n",
    "\n",
    "    filtered_binary_A = np.zeros_like(labels_watershed)\n",
    "    #filtered_binary_A = np.zeros_like(binary_A)\n",
    "    for prop in region_props_A:\n",
    "        #if prop.area <= 5000 and prop.area > 2000:\n",
    "        #if prop.area > 3000 and prop.area < 6000:\n",
    "        if prop.area > 0:\n",
    "            min_row, min_col, max_row, max_col = prop.bbox\n",
    "            #filtered_binary_A[min_row:max_row, min_col:max_col] = (region_labels_A[min_row:max_row, min_col:max_col] == prop.label)\n",
    "            filtered_binary_A[min_row:max_row, min_col:max_col] = (labels_watershed[min_row:max_row, min_col:max_col] == prop.label)\n",
    "            \n",
    "    filtered_binary_A = (filtered_binary_A > 0).astype(np.uint8) * 255  # Convert back to uint8\n",
    "    \n",
    "    # Create a DataFrame for the regions with their area in µm²\n",
    "    region_area = pd.DataFrame({\n",
    "        \"Region_Label\": [region.label for region in region_props_A],\n",
    "        \"Region_Area (pixels)\": [region.area for region in region_props_A],\n",
    "        \"Region_Area (µm²)\": [region.area * (pixel_to_um ** 2) for region in region_props_A]\n",
    "    })\n",
    "    \n",
    "    region_area_df = region_area[region_area[\"Region_Area (µm²)\"] > 0]\n",
    "\n",
    "    # Calculate the total area in µm²\n",
    "    total_area = region_area_df[\"Region_Area (µm²)\"].sum()\n",
    "\n",
    "    # Add the total area to the DataFrame\n",
    "    region_area_df.loc[\"Total\"] = [\"Total\", \"\", total_area]\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    region_area_excel_path = os.path.join(output_folder, f\"{os.path.splitext(bf_file)[0]}_Region_Area_in_um2.xlsx\")\n",
    "    region_area_df.to_excel(region_area_excel_path, index=False)\n",
    "\n",
    "    print(f\"Saved region areas for {bf_file} to {region_area_excel_path}\")\n",
    "\n",
    "    # Process Image B (contrast enhancement and thresholding)\n",
    "    grayB = rgb2gray(imageB)\n",
    "    grayB = exposure.equalize_adapthist(grayB)\n",
    "    grayB = cv2.bilateralFilter((grayB * 255).astype(np.uint8), 9, 75, 75)\n",
    "    mean_intensity = np.mean(grayB)\n",
    "    std_intensity = np.std(grayB)\n",
    "    dynamic_multiplier = 3 if std_intensity < 30 else (4 if std_intensity < 70 else 6)\n",
    "    dynamic_threshold = mean_intensity + dynamic_multiplier * std_intensity\n",
    "    binary_B = (grayB > dynamic_threshold).astype(np.uint8)\n",
    "    \n",
    "    # Plot both binary_A and binary_B\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Adjust indexing for 2x2 grid of axes\n",
    "    #ax[0, 0].imshow(binary_min_B, cmap='gray')\n",
    "    #ax[0, 0].set_title('Min Threshold Binary')\n",
    "    #ax[0, 0].axis('off')  # Hide axes\n",
    "\n",
    "    #ax[0, 1].imshow(binary_max_B, cmap='gray')\n",
    "    #ax[0, 1].set_title('Max Threshold Binary')\n",
    "    #ax[0, 1].axis('off')  # Hide axes\n",
    "\n",
    "    ax[0].imshow(filtered_binary_A, cmap='gray')\n",
    "    ax[0].set_title('Binary A')\n",
    "    ax[0].axis('off')  # Hide axes\n",
    "\n",
    "    ax[1].imshow(binary_B, cmap='gray')\n",
    "    ax[1].set_title('Binary B')\n",
    "    ax[1].axis('off')  # Hide axes\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Resize for alignment\n",
    "    filtered_binary_A_resized = cv2.resize(binary_A, (2048, 2048), interpolation=cv2.INTER_AREA)\n",
    "    binary_B_resized = cv2.resize(binary_B, (2048, 2048), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Overlap calculation\n",
    "    overlap = (np.logical_and(filtered_binary_A_resized > 0, binary_B_resized > 0)).astype(np.uint8) * 255\n",
    "    \n",
    "    # Calculate the total overlap area in pixels\n",
    "    #overlap_area = np.sum(overlap > 0)\n",
    "\n",
    "    # Save overlap results\n",
    "    #if overlap_area < 400:\n",
    "    overlap_path = os.path.join(output_folder, f\"{os.path.splitext(bf_file)[0]}_Overlap.png\")\n",
    "    cv2.imwrite(overlap_path, overlap)\n",
    "\n",
    "    #--------------------------------------------------------------\n",
    "    # Save clustering information\n",
    "    region_to_cell_mapping = []\n",
    "    cell_labels = label(filtered_binary_A_resized)\n",
    "    cell_props = regionprops(cell_labels)\n",
    "    region_labels = label(overlap)\n",
    "    region_props = regionprops(region_labels)\n",
    "\n",
    "    for region in region_props:\n",
    "        region_coords = set(tuple(coord) for coord in region.coords)\n",
    "        best_match_cell = None\n",
    "        max_overlap = 0\n",
    "        for cell in cell_props:\n",
    "            cell_coords = set(tuple(coord) for coord in cell.coords)\n",
    "            overlap_area = len(region_coords & cell_coords)\n",
    "            if overlap_area > max_overlap:\n",
    "                max_overlap = overlap_area\n",
    "                best_match_cell = cell.label\n",
    "        region_to_cell_mapping.append({\n",
    "            \"Region_Label\": region.label,\n",
    "            \"Associated_Cell\": best_match_cell,\n",
    "            \"Overlap (pixels)\": max_overlap,\n",
    "            \"Region_Area (pixels)\": region.area,\n",
    "            \"Region_Area (µm²)\": region.area * (pixel_to_um ** 2)\n",
    "        })\n",
    "\n",
    "    # Save region-to-cell mapping as CSV\n",
    "    df_mapp = pd.DataFrame(region_to_cell_mapping)\n",
    "    df_mapping = df_mapp[df_mapp[\"Region_Area (µm²)\"] > 0]\n",
    "\n",
    "    # Add additional stats to the DataFrame\n",
    "    df_mapping[\"Associated_Cell_Count\"] = df_mapping[\"Associated_Cell\"].map(df_mapping[\"Associated_Cell\"].value_counts())\n",
    "    total_distinct_cells = df_mapping[\"Associated_Cell\"].nunique()\n",
    "    df_mapping[\"Total_Distinct_Cells\"] = total_distinct_cells\n",
    "    df_mapping.loc[\"Total\", \"Region_Area (µm²)\"] = df_mapping[\"Region_Area (µm²)\"].sum()\n",
    "\n",
    "    # Save the updated CSV\n",
    "    mapping_excel_path = os.path.join(output_folder, f\"{os.path.splitext(bf_file)[0]}_Region_Cell_Mapping.xlsx\")\n",
    "    df_mapping.to_excel(mapping_excel_path, index=False)\n",
    "    \n",
    "    # Group by Associated_Cell and count regions, then calculate percentages\n",
    "    cell_grouped_df = pd.DataFrame(region_to_cell_mapping)\n",
    "    cell_region_count = cell_grouped_df.groupby(\"Associated_Cell\")[\"Region_Label\"].count().reset_index()\n",
    "    cell_region_count.columns = [\"Associated_Cell\", \"Region_Count\"]\n",
    "    total_region_count = cell_region_count[\"Region_Count\"].sum()\n",
    "    cell_region_count[\"Percentage\"] = (cell_region_count[\"Region_Count\"] / total_region_count) * 100\n",
    "\n",
    "    # Remove columns \"D\" and \"E\" from the first sheet (final grouped DataFrame)\n",
    "    final_grouped_df = cell_region_count.drop(columns=[\"Percentage\"])\n",
    "    \n",
    "    # Create a new DataFrame to count how many times each Associated_Cell has the same value as Region_Label\n",
    "    region_to_associated_cell_mapping = []\n",
    "    for region in region_to_cell_mapping:\n",
    "        region_label = region[\"Region_Label\"]\n",
    "        associated_cell = region[\"Associated_Cell\"]\n",
    "        # Check if the Associated Cell matches the Region Label\n",
    "        region_to_associated_cell_mapping.append({\n",
    "            \"Region_Label\": region_label,\n",
    "            \"Associated_Cell\": associated_cell\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    region_association_df = pd.DataFrame(region_to_associated_cell_mapping)\n",
    "\n",
    "    # Count how many times each Associated_Cell has the same value as the Region_Label\n",
    "    matching_cell_count = region_association_df[region_association_df[\"Region_Label\"] == region_association_df[\"Associated_Cell\"]].groupby(\"Region_Label\").size().reset_index(name=\"Matching_Associated_Cell_Count\")\n",
    "\n",
    "    # Merge the new data with the original cell_region_count dataframe\n",
    "    final_grouped_df = pd.merge(final_grouped_df, matching_cell_count, how=\"left\", left_on=\"Associated_Cell\", right_on=\"Region_Label\")\n",
    "\n",
    "    # Define the output path with .xlsx extension instead of .csv\n",
    "    grouped_xlsx_path = os.path.join(output_folder, f\"{os.path.splitext(bf_file)[0]}_Grouped_by_Cell_Region_Count_with_Percentage_and_Matching.xlsx\")\n",
    "\n",
    "    # Saving to an Excel file with multiple sheets\n",
    "    with pd.ExcelWriter(grouped_xlsx_path, engine='xlsxwriter') as writer:\n",
    "        # Save the original DataFrame (final_grouped_df) to the first sheet\n",
    "        final_grouped_df.to_excel(writer, sheet_name='Cell_Region_Count', index=False)  # Shortened sheet name\n",
    "        \n",
    "        # Save the grouped Region_Count DataFrame to the second sheet, including percentages\n",
    "        region_count_grouped = cell_region_count.groupby('Region_Count').size().reset_index(name='Region_Count_Frequency')\n",
    "        \n",
    "        # Remove the total count entry\n",
    "        region_count_grouped = region_count_grouped[region_count_grouped['Region_Count'] != region_count_grouped['Region_Count'].sum()]\n",
    "\n",
    "        # Add percentages to the Region_Count Grouped sheet\n",
    "        total_region_count = region_count_grouped['Region_Count_Frequency'].sum()\n",
    "        region_count_grouped['Percentage'] = (region_count_grouped['Region_Count_Frequency'] / total_region_count) * 100\n",
    "        \n",
    "        region_count_grouped.to_excel(writer, sheet_name='Region_Count_Grouped', index=False)  # Shortened sheet name\n",
    "\n",
    "    print(f\"Saved results for {bf_file} to {grouped_xlsx_path}\")\n",
    "\n",
    "    #--------------------------------------------------------------\n",
    "    # Visualization\n",
    "    annotated_image = imageA.copy()\n",
    "    for mapping in region_to_cell_mapping:\n",
    "        region_label = mapping[\"Region_Label\"]\n",
    "        associated_cell = mapping[\"Associated_Cell\"]\n",
    "        if associated_cell:\n",
    "            region = next(r for r in region_props if r.label == region_label)\n",
    "            min_row, min_col, max_row, max_col = region.bbox\n",
    "            cv2.rectangle(annotated_image, (min_col, min_row), (max_col, max_row), (0, 255, 0), 2)\n",
    "            cv2.putText(\n",
    "                annotated_image,\n",
    "                f\"Cell {associated_cell}\",\n",
    "                (min_col, min_row - 5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.3,\n",
    "                (255, 0, 0),\n",
    "                1\n",
    "            )\n",
    "            \n",
    "    # Plot both binary_A and binary_B\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Show binary_A\n",
    "    ax[0].imshow(annotated_image, cmap='gray')\n",
    "    ax[0].set_title('Detections')\n",
    "    ax[0].axis('off')  # Hide axes\n",
    "\n",
    "    # Show binary_B\n",
    "    ax[1].imshow(overlap, cmap='gray')\n",
    "    ax[1].set_title('Coincidences')\n",
    "    ax[1].axis('off')  # Hide axes\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save annotated image\n",
    "    annotated_image_path = os.path.join(output_folder, f\"{os.path.splitext(bf_file)[0]}_Annotated_Image_with_Clustering.png\")\n",
    "    cv2.imwrite(annotated_image_path, annotated_image)\n",
    "\n",
    "    print(f\"Saved results for {bf_file} to {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec14181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d48228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
